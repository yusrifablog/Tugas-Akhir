{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data_train_nostopword.csv', sep=';')\n",
    "data_test = pd.read_csv('data_test_nostopword.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dair dulu penasaran banget sama skincare ini k...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dari awal ngincer ini karena banyak yang bilan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aku suka sekali tabirsurya ini tekstur ringan ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pernah nyobain ini pas muka lagi stress ny dan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paling suka sama gokujyun losion untuk merek h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  price  packaging  \\\n",
       "0  dair dulu penasaran banget sama skincare ini k...     -1          0   \n",
       "1  dari awal ngincer ini karena banyak yang bilan...      0          0   \n",
       "2  aku suka sekali tabirsurya ini tekstur ringan ...      0          1   \n",
       "3  pernah nyobain ini pas muka lagi stress ny dan...      0          0   \n",
       "4  paling suka sama gokujyun losion untuk merek h...      1          0   \n",
       "\n",
       "   product  aroma  \n",
       "0      0.0      0  \n",
       "1      1.0      0  \n",
       "2      1.0      0  \n",
       "3     -1.0      0  \n",
       "4      1.0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>produk favorit banget enak dipake plus tidak p...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awal agak lengket pas baru dipake tapi untuk h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minyak kontrol lumayan bisa ngempesin jerawat ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>favorite banget selain harga terjangkau banget...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ini adalah exfoliant toner yang saya pakai bag...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  price  packaging  \\\n",
       "0  produk favorit banget enak dipake plus tidak p...     -1          0   \n",
       "1  awal agak lengket pas baru dipake tapi untuk h...      1          0   \n",
       "2  minyak kontrol lumayan bisa ngempesin jerawat ...      1          0   \n",
       "3  favorite banget selain harga terjangkau banget...      1          0   \n",
       "4  ini adalah exfoliant toner yang saya pakai bag...      0          0   \n",
       "\n",
       "   product  aroma  \n",
       "0      1.0      0  \n",
       "1      0.0      0  \n",
       "2     -1.0      0  \n",
       "3      1.0      0  \n",
       "4      1.0      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_text    0\n",
       "price          0\n",
       "packaging      0\n",
       "product        0\n",
       "aroma          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_text    0\n",
       "price          0\n",
       "packaging      0\n",
       "product        0\n",
       "aroma          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train['review_text']\n",
    "X_test = data_test['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "fitur_train = TfidfVectorizer().fit(X_train)\n",
    "tfidf_train = fitur_train.transform(X_train).toarray()\n",
    "tfidf_test = fitur_train.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitur_tfidf(tfidf, fitur):\n",
    "    terms = tfidf.get_feature_names()\n",
    "    sums = fitur.sum(axis = 0)\n",
    "\n",
    "    data = []\n",
    "    for col, term in enumerate(terms):\n",
    "        data.append((term, sums[col] ))\n",
    "    ranking = pd.DataFrame(data, columns=['Terms','TF-IDF'])\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tfidf_tr = get_fitur_tfidf(fitur_train, tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7540, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tfidf_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SELECTION CHI SQUARE\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chi_tr = tfidf_train\n",
    "x_chi_test = tfidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_chi_tr = np.array(data_train[['price','packaging','aroma','product']])\n",
    "#y_chi_test = np.array(data_test[['price','packaging','aroma','product']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_price_tr = (data_train['price'])\n",
    "y_packaging_tr = (data_train['packaging'])\n",
    "y_product_tr = (data_train['product'])\n",
    "y_aroma_tr = (data_train['aroma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_price_test = (data_test['price'])\n",
    "y_packaging_test = (data_test['packaging'])\n",
    "y_product_test = (data_test['product'])\n",
    "y_aroma_test = (data_test['aroma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_price_tr = SelectKBest(score_func=chi2, k=76).fit_transform(x_chi_tr, y_price_tr)\n",
    "chi_packaging_tr = SelectKBest(score_func=chi2, k=76).fit_transform(x_chi_tr, y_packaging_tr)\n",
    "chi_product_tr = SelectKBest(score_func=chi2, k=76).fit_transform(x_chi_tr, y_product_tr)\n",
    "chi_aroma_tr = SelectKBest(score_func=chi2, k=76).fit_transform(x_chi_tr, y_aroma_tr)\n",
    "\n",
    "\n",
    "chi_price_test = SelectKBest(score_func=chi2, k=76).fit_transform(x_chi_test, y_price_test)\n",
    "chi_packaging_test = SelectKBest(score_func=chi2, k=76).fit_transform(x_chi_test, y_packaging_test)\n",
    "chi_product_test = SelectKBest(score_func=chi2, k=76).fit_transform(x_chi_test, y_product_test)\n",
    "chi_aroma_test = SelectKBest(score_func=chi2, k=76).fit_transform(x_chi_test, y_aroma_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#aspek price\n",
    "knn_price_7 = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "\n",
    "knn_price_7.fit(chi_price_tr, y_price_tr)\n",
    "\n",
    "\n",
    "predictions_price_7 = knn_price_7.predict(chi_price_test)\n",
    "\n",
    "#aspek packaging\n",
    "\n",
    "knn_packaging_7 = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "knn_packaging_7.fit(chi_packaging_tr, y_packaging_tr)\n",
    "\n",
    "predictions_packaging_7 = knn_packaging_7.predict(chi_packaging_test)\n",
    "\n",
    "#aspek product\n",
    "\n",
    "knn_product_7 = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "\n",
    "\n",
    "knn_product_7.fit(chi_product_tr, y_product_tr)\n",
    "\n",
    "\n",
    "\n",
    "predictions_product_7 = knn_product_7.predict(chi_product_test)\n",
    "\n",
    "#aspek aroma\n",
    "\n",
    "knn_aroma_7 = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "\n",
    "knn_aroma_7.fit(chi_aroma_tr, y_aroma_tr)\n",
    "\n",
    "\n",
    "predictions_aroma_7 = knn_aroma_7.predict(chi_aroma_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== PRICE ===================\n",
      "Nilai Model price K-NN pada K-50           : 57.1969696969697 %\n",
      "                                                                             \n",
      "============= PACKAGING ================\n",
      "Nilai Model packaging K-NN pada K-50       : 84.72222222222221 %\n",
      "                                                                             \n",
      "============= PRODUCT ================\n",
      "Nilai Model product K-NN pada K-50         : 67.8030303030303 %\n",
      "                                                                             \n",
      "============= AROMA ================\n",
      "Nilai Model aroma K-NN pada K-50           : 79.54545454545455 %\n"
     ]
    }
   ],
   "source": [
    "#Nilai price\n",
    "\n",
    "knn7_price_skor=knn_price_7.score(chi_price_test,y_price_test)\n",
    "\n",
    "#nilai packaging\n",
    "\n",
    "knn7_packaging_skor=knn_packaging_7.score(chi_packaging_test,y_packaging_test)\n",
    "\n",
    "#nilai product\n",
    "\n",
    "knn7_product_skor=knn_product_7.score(chi_product_test,y_product_test)\n",
    "\n",
    "#nilai aroma\n",
    "\n",
    "knn7_aroma_skor=knn_aroma_7.score(chi_aroma_test,y_aroma_test)\n",
    "\n",
    "print('=============== PRICE ===================')\n",
    "\n",
    "print('Nilai Model price K-NN pada K-50           :',knn7_price_skor * 100 ,'%')\n",
    "\n",
    "print('                                                                             ')\n",
    "print('============= PACKAGING ================')\n",
    "\n",
    "print('Nilai Model packaging K-NN pada K-50       :',knn7_packaging_skor * 100 ,'%')\n",
    "\n",
    "print('                                                                             ')\n",
    "print('============= PRODUCT ================')\n",
    "\n",
    "print('Nilai Model product K-NN pada K-50         :',knn7_product_skor * 100 ,'%')\n",
    "\n",
    "print('                                                                             ')\n",
    "print('============= AROMA ================')\n",
    "\n",
    "print('Nilai Model aroma K-NN pada K-50           :',knn7_aroma_skor * 100 ,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "#from sklearn.metrics import  multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0 139  13]\n",
      " [  0 407  12]\n",
      " [  4 171  46]]\n",
      "\n",
      "Accuracy: 0.57\n",
      "\n",
      "Micro Precision: 0.57\n",
      "Micro Recall: 0.57\n",
      "Micro F1-score: 0.57\n",
      "\n",
      "Macro Precision: 0.41\n",
      "Macro Recall: 0.39\n",
      "Macro F1-score: 0.34\n",
      "\n",
      "Weighted Precision: 0.48\n",
      "Weighted Recall: 0.57\n",
      "Weighted F1-score: 0.47\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       152\n",
      "           0       0.57      0.97      0.72       419\n",
      "           1       0.65      0.21      0.32       221\n",
      "\n",
      "    accuracy                           0.57       792\n",
      "   macro avg       0.41      0.39      0.34       792\n",
      "weighted avg       0.48      0.57      0.47       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Price Pada K = 50\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_price_test,predictions_price_7)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_price_test,predictions_price_7)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_7, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_7, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_7, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_7, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_7, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_7, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_7, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_7, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_price_test,predictions_price_7, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_price_test,predictions_price_7, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  39   2]\n",
      " [  0 670   2]\n",
      " [  0  78   1]]\n",
      "\n",
      "Accuracy: 0.85\n",
      "\n",
      "Micro Precision: 0.85\n",
      "Micro Recall: 0.85\n",
      "Micro F1-score: 0.85\n",
      "\n",
      "Macro Precision: 0.35\n",
      "Macro Recall: 0.34\n",
      "Macro F1-score: 0.31\n",
      "\n",
      "Weighted Precision: 0.74\n",
      "Weighted Recall: 0.85\n",
      "Weighted F1-score: 0.78\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        41\n",
      "           0       0.85      1.00      0.92       672\n",
      "           1       0.20      0.01      0.02        79\n",
      "\n",
      "    accuracy                           0.85       792\n",
      "   macro avg       0.35      0.34      0.31       792\n",
      "weighted avg       0.74      0.85      0.78       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Packaging pada K= 50\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_packaging_test,predictions_packaging_7)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_packaging_test,predictions_packaging_7)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_7, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_7, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_7, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_7, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_7, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_7, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_7, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_7, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_packaging_test,predictions_packaging_7, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_packaging_test,predictions_packaging_7, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  3   3 129]\n",
      " [  2   0 119]\n",
      " [  0   2 534]]\n",
      "\n",
      "Accuracy: 0.68\n",
      "\n",
      "Micro Precision: 0.68\n",
      "Micro Recall: 0.68\n",
      "Micro F1-score: 0.68\n",
      "\n",
      "Macro Precision: 0.43\n",
      "Macro Recall: 0.34\n",
      "Macro F1-score: 0.28\n",
      "\n",
      "Weighted Precision: 0.56\n",
      "Weighted Recall: 0.68\n",
      "Weighted F1-score: 0.56\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.02      0.04       135\n",
      "           0       0.00      0.00      0.00       121\n",
      "           1       0.68      1.00      0.81       536\n",
      "\n",
      "    accuracy                           0.68       792\n",
      "   macro avg       0.43      0.34      0.28       792\n",
      "weighted avg       0.56      0.68      0.56       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 50\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_product_test,predictions_product_7)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_product_test,predictions_product_7)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_7, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_7, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_7, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_7, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_7, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_7, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_7, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_7, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_product_test,predictions_product_7, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_product_test,predictions_product_7, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  2  35   3]\n",
      " [  0 614   1]\n",
      " [  0 123  14]]\n",
      "\n",
      "Accuracy: 0.80\n",
      "\n",
      "Micro Precision: 0.80\n",
      "Micro Recall: 0.80\n",
      "Micro F1-score: 0.80\n",
      "\n",
      "Macro Precision: 0.86\n",
      "Macro Recall: 0.38\n",
      "Macro F1-score: 0.39\n",
      "\n",
      "Weighted Precision: 0.80\n",
      "Weighted Recall: 0.80\n",
      "Weighted F1-score: 0.72\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.05      0.10        40\n",
      "           0       0.80      1.00      0.89       615\n",
      "           1       0.78      0.10      0.18       137\n",
      "\n",
      "    accuracy                           0.80       792\n",
      "   macro avg       0.86      0.38      0.39       792\n",
      "weighted avg       0.80      0.80      0.72       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Aroma Pada K=50\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_aroma_test,predictions_aroma_7)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_aroma_test,predictions_aroma_7)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_7, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_7, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_7, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_7, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_7, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_7, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_7, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_7, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_aroma_test,predictions_aroma_7, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_aroma_test,predictions_aroma_7, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
