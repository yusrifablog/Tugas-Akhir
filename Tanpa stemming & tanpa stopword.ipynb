{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "# text preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import requests\n",
    "import io\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import re # regular expression\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory # stemming indonesian language\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer # to create Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # tfid Vector \n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score # confussion matrix\n",
    "from sklearn.preprocessing import LabelEncoder # to convert classes to number \n",
    "from sklearn.model_selection import train_test_split  # for splitting data \n",
    "from sklearn.metrics import accuracy_score # to calculate accuracy\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'before_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>838</td>\n",
       "      <td>ini enak banget dipakainya, enteng banget diwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1166</td>\n",
       "      <td>the description is quite right. produk ini ema...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1421</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        review_text  price  \\\n",
       "0        708  sunscreen termahal yang pernah gue beli ini ka...     -1   \n",
       "1        838  ini enak banget dipakainya, enteng banget diwa...      0   \n",
       "2       1166  the description is quite right. produk ini ema...      0   \n",
       "3       1374  bisa untuk wajah dan badan dengan harga yang s...      1   \n",
       "4       1421  saya beli produk ini karena suka banget wangin...     -1   \n",
       "\n",
       "   packaging  product  aroma  \n",
       "0          0      1.0      0  \n",
       "1          0      1.0      0  \n",
       "2          0      1.0      1  \n",
       "3          1      1.0      0  \n",
       "4          0      0.0      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      0\n",
       "review_text    0\n",
       "price          0\n",
       "packaging      0\n",
       "product        1\n",
       "aroma          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      0\n",
       "review_text    0\n",
       "price          0\n",
       "packaging      0\n",
       "product        0\n",
       "aroma          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.fillna(method=\"ffill\")\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>838</td>\n",
       "      <td>ini enak banget dipakainya, enteng banget diwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1166</td>\n",
       "      <td>the description is quite right. produk ini ema...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1421</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        review_text  price  \\\n",
       "0        708  sunscreen termahal yang pernah gue beli ini ka...     -1   \n",
       "1        838  ini enak banget dipakainya, enteng banget diwa...      0   \n",
       "2       1166  the description is quite right. produk ini ema...      0   \n",
       "3       1374  bisa untuk wajah dan badan dengan harga yang s...      1   \n",
       "4       1421  saya beli produk ini karena suka banget wangin...     -1   \n",
       "\n",
       "   packaging  product  aroma  \n",
       "0          0      1.0      0  \n",
       "1          0      1.0      0  \n",
       "2          0      1.0      1  \n",
       "3          1      1.0      0  \n",
       "4          0      0.0      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>838</td>\n",
       "      <td>ini enak banget dipakainya, enteng banget diwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ini enak banget dipakainya enteng banget diwaj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1166</td>\n",
       "      <td>the description is quite right. produk ini ema...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>the description is quite right produk ini eman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1421</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        review_text  price  \\\n",
       "0        708  sunscreen termahal yang pernah gue beli ini ka...     -1   \n",
       "1        838  ini enak banget dipakainya, enteng banget diwa...      0   \n",
       "2       1166  the description is quite right. produk ini ema...      0   \n",
       "3       1374  bisa untuk wajah dan badan dengan harga yang s...      1   \n",
       "4       1421  saya beli produk ini karena suka banget wangin...     -1   \n",
       "\n",
       "   packaging  product  aroma  \\\n",
       "0          0      1.0      0   \n",
       "1          0      1.0      0   \n",
       "2          0      1.0      1   \n",
       "3          1      1.0      0   \n",
       "4          0      0.0      1   \n",
       "\n",
       "                                          Clean_text  \n",
       "0  sunscreen termahal yang pernah gue beli ini ka...  \n",
       "1  ini enak banget dipakainya enteng banget diwaj...  \n",
       "2  the description is quite right produk ini eman...  \n",
       "3  bisa untuk wajah dan badan dengan harga yang s...  \n",
       "4  saya beli produk ini karena suka banget wangin...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# casefolding \n",
    "\n",
    "def clean(dataset):\n",
    "  temp_text = []\n",
    "\n",
    "  for txt in dataset:\n",
    "    # removal of @name[mention]\n",
    "    txt = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", txt)\n",
    "\n",
    "    # removal of links[https://blabala.com]\n",
    "    # tw = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"\", tw)\n",
    "    txt = re.sub(r\"http\\S+\", \"\", txt)\n",
    "\n",
    "    # removal of new line\n",
    "    txt = re.sub('\\n', '', txt)\n",
    "\n",
    "    # removal of RT\n",
    "    txt = re.sub('RT', '', txt)\n",
    "\n",
    "    # removal of punctuations and numbers\n",
    "    txt = re.sub(\"[^a-zA-Z^']\", \" \", txt)\n",
    "    txt = re.sub(\" {2,}\", \" \", txt)\n",
    "\n",
    "    # remove leading and trailing whitespace\n",
    "    txt = txt.strip()\n",
    "\n",
    "    # remove whitespace with a single space\n",
    "    txt = re.sub(r'\\s+', ' ', txt)\n",
    "\n",
    "    # convert text to Lowercase\n",
    "    text = txt.lower();\n",
    "    temp_text.append(txt)\n",
    "  return temp_text \n",
    "\n",
    "dataset['Clean_text'] = clean(dataset['review_text'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[sunscreen, termahal, yang, pernah, gue, beli,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>838</td>\n",
       "      <td>ini enak banget dipakainya, enteng banget diwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ini, enak, banget, dipakainya, enteng, banget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1166</td>\n",
       "      <td>the description is quite right. produk ini ema...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, description, is, quite, right, produk, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[bisa, untuk, wajah, dan, badan, dengan, harga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1421</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[saya, beli, produk, ini, karena, suka, banget...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        review_text  price  \\\n",
       "0        708  sunscreen termahal yang pernah gue beli ini ka...     -1   \n",
       "1        838  ini enak banget dipakainya, enteng banget diwa...      0   \n",
       "2       1166  the description is quite right. produk ini ema...      0   \n",
       "3       1374  bisa untuk wajah dan badan dengan harga yang s...      1   \n",
       "4       1421  saya beli produk ini karena suka banget wangin...     -1   \n",
       "\n",
       "   packaging  product  aroma  \\\n",
       "0          0      1.0      0   \n",
       "1          0      1.0      0   \n",
       "2          0      1.0      1   \n",
       "3          1      1.0      0   \n",
       "4          0      0.0      1   \n",
       "\n",
       "                                          Clean_text  \n",
       "0  [sunscreen, termahal, yang, pernah, gue, beli,...  \n",
       "1  [ini, enak, banget, dipakainya, enteng, banget...  \n",
       "2  [the, description, is, quite, right, produk, i...  \n",
       "3  [bisa, untuk, wajah, dan, badan, dengan, harga...  \n",
       "4  [saya, beli, produk, ini, karena, suka, banget...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TOKENISASI\n",
    "def token(dataset):\n",
    "  return dataset.apply(nltk.word_tokenize)\n",
    "\n",
    "dataset['Clean_text'] = token(dataset['Clean_text'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>838</td>\n",
       "      <td>ini enak banget dipakainya, enteng banget diwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ini enak banget dipakainya enteng banget diwaj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1166</td>\n",
       "      <td>the description is quite right. produk ini ema...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>the description is quite right produk ini eman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1421</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        review_text  price  \\\n",
       "0        708  sunscreen termahal yang pernah gue beli ini ka...     -1   \n",
       "1        838  ini enak banget dipakainya, enteng banget diwa...      0   \n",
       "2       1166  the description is quite right. produk ini ema...      0   \n",
       "3       1374  bisa untuk wajah dan badan dengan harga yang s...      1   \n",
       "4       1421  saya beli produk ini karena suka banget wangin...     -1   \n",
       "\n",
       "   packaging  product  aroma  \\\n",
       "0          0      1.0      0   \n",
       "1          0      1.0      0   \n",
       "2          0      1.0      1   \n",
       "3          1      1.0      0   \n",
       "4          0      0.0      1   \n",
       "\n",
       "                                          Clean_text  \n",
       "0  sunscreen termahal yang pernah gue beli ini ka...  \n",
       "1  ini enak banget dipakainya enteng banget diwaj...  \n",
       "2  the description is quite right produk ini eman...  \n",
       "3  bisa untuk wajah dan badan dengan harga yang s...  \n",
       "4  saya beli produk ini karena suka banget wangin...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Clean_text'] = dataset['Clean_text'].apply(lambda x: \" \".join(x) if isinstance(x, list) else x)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_word = requests.get('https://raw.githubusercontent.com/louisowen6/NLP_bahasa_resources/master/combined_slang_words.txt').text\n",
    "dict_slang = eval(slang_word)\n",
    "\n",
    "df_acronym = pd.read_csv('https://raw.githubusercontent.com/ramaprakoso/analisis-sentimen/master/kamus/acronym.txt', header=None, sep='=')\n",
    "df_acronym.columns = ['Singkatan', 'kepanjangan']\n",
    "df_acronym.kepanjangan = df_acronym.kepanjangan.apply(lambda x: x.strip().lower())\n",
    "df_acronym.Singkatan = df_acronym.Singkatan.apply(lambda x: x.strip().lower())\n",
    "dict_singkatan = pd.Series(df_acronym.kepanjangan.values,index=df_acronym.Singkatan).to_dict()\n",
    "\n",
    "dict_clean = {**dict_singkatan, **dict_slang}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_slang_singkatan(review_text, dict_clean=dict_clean):\n",
    "  regex = r\"\\b(?:\"+\"|\".join(re.escape(word) for word in dict_clean) + r\")\\b\"\n",
    "  reobj = re.compile(regex, re.I)\n",
    "  \n",
    "  return reobj.sub(lambda x:dict_clean[x.group(0)], review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all(x, dict_clean=dict_clean):\n",
    "  x = preprocessing_slang_singkatan(x, dict_clean=dict_clean)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3960/3960 [00:30<00:00, 131.88it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset['Clean_text'] = dataset.Clean_text.progress_apply(lambda x: clean_all(x, dict_clean=dict_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('data_preprocessing_tanpastopword_tanpastemming.csv', index=False, sep= ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer, CountVectorizer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_vectorize = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.49248889, 0.        , 0.40264194, 0.77157901,\n",
       "        0.        ],\n",
       "       [0.77157901, 0.49248889, 0.        , 0.40264194, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.49248889, 0.        , 0.40264194, 0.        ,\n",
       "        0.77157901],\n",
       "       [0.        , 0.        , 0.88654763, 0.46263733, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'Pusing satu kali',\n",
    "    'Pusing dua kali',\n",
    "    'Pusing tiga kali',\n",
    "    'Pusing lagi']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# contoh\n",
    "a = vectorizer.fit_transform(corpus)\n",
    "a.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3960, 10963)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dataset['Clean_text']\n",
    "# Count TF_IDF Vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vector = count_vectorizer.fit_transform(dataset['Clean_text'])\n",
    "count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7417)\t0.04546082596079838\n",
      "  (0, 5801)\t0.10022107864701454\n",
      "  (0, 4215)\t0.0497239334950299\n",
      "  (0, 946)\t0.17478849883268197\n",
      "  (0, 8096)\t0.06430206170959138\n",
      "  (0, 7998)\t0.17592609474249327\n",
      "  (0, 1722)\t0.19973861733531917\n",
      "  (0, 1994)\t0.0363582289446547\n",
      "  (0, 2775)\t0.15640735531267105\n",
      "  (0, 9959)\t0.1381351394396345\n",
      "  (0, 10611)\t0.14524491086503974\n",
      "  (0, 1026)\t0.08851750056979785\n",
      "  (0, 6660)\t0.06627142373460529\n",
      "  (0, 5966)\t0.21874527692521886\n",
      "  (0, 9357)\t0.10262102089780652\n",
      "  (0, 10185)\t0.11032370654189423\n",
      "  (0, 4152)\t0.2128484357635605\n",
      "  (0, 1240)\t0.23742429129686818\n",
      "  (0, 7770)\t0.21731957279211928\n",
      "  (0, 1552)\t0.14606200652283324\n",
      "  (0, 10773)\t0.13430150011000042\n",
      "  (0, 6261)\t0.15305690659934088\n",
      "  (0, 10220)\t0.12313365965772284\n",
      "  (0, 9505)\t0.1121956449073298\n",
      "  (0, 3849)\t0.18239836846897378\n",
      "  :\t:\n",
      "  (3959, 10515)\t0.06880839253835738\n",
      "  (3959, 9913)\t0.06889003465547967\n",
      "  (3959, 4146)\t0.06868645843912446\n",
      "  (3959, 6266)\t0.127276554905328\n",
      "  (3959, 9142)\t0.07429063528889157\n",
      "  (3959, 9181)\t0.11180372835788928\n",
      "  (3959, 1410)\t0.05859198402395937\n",
      "  (3959, 762)\t0.16389243940852058\n",
      "  (3959, 5924)\t0.07807865962608997\n",
      "  (3959, 2849)\t0.077898021814923\n",
      "  (3959, 9736)\t0.09480352883292745\n",
      "  (3959, 10696)\t0.07313608780829738\n",
      "  (3959, 9847)\t0.07873953075091317\n",
      "  (3959, 4505)\t0.042599532397367884\n",
      "  (3959, 5236)\t0.057736875021203886\n",
      "  (3959, 9789)\t0.10439882466660544\n",
      "  (3959, 6993)\t0.15257520148741563\n",
      "  (3959, 651)\t0.04109792312092587\n",
      "  (3959, 7417)\t0.07370570279369047\n",
      "  (3959, 1994)\t0.08842147365548912\n",
      "  (3959, 6660)\t0.053722977511556844\n",
      "  (3959, 4080)\t0.05559725712702547\n",
      "  (3959, 7094)\t0.0561273328238813\n",
      "  (3959, 4026)\t0.05598347889642009\n",
      "  (3959, 10891)\t0.06635505484297664\n"
     ]
    }
   ],
   "source": [
    "a = dataset['Clean_text']\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer = tfidf_vectorizer.fit_transform(a)\n",
    "print(tfidf_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3960, 10963)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aceh</th>\n",
       "      <th>acid</th>\n",
       "      <th>acne</th>\n",
       "      <th>ada</th>\n",
       "      <th>adalah</th>\n",
       "      <th>adat</th>\n",
       "      <th>adem</th>\n",
       "      <th>administrasi</th>\n",
       "      <th>advanced</th>\n",
       "      <th>affordable</th>\n",
       "      <th>...</th>\n",
       "      <th>would</th>\n",
       "      <th>wow</th>\n",
       "      <th>yaa</th>\n",
       "      <th>yah</th>\n",
       "      <th>yaitu</th>\n",
       "      <th>yang</th>\n",
       "      <th>yes</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aceh  acid  acne  ada  adalah  adat  adem  administrasi  advanced  \\\n",
       "0   0.0   0.0   0.0  0.0     0.0   0.0   0.0           0.0       0.0   \n",
       "1   0.0   0.0   0.0  0.0     0.0   0.0   0.0           0.0       0.0   \n",
       "2   0.0   0.0   0.0  0.0     0.0   0.0   0.0           0.0       0.0   \n",
       "3   0.0   0.0   0.0  0.0     0.0   0.0   0.0           0.0       0.0   \n",
       "4   0.0   0.0   0.0  0.0     0.0   0.0   0.0           0.0       0.0   \n",
       "\n",
       "   affordable  ...  would  wow  yaa  yah  yaitu      yang  yes  you  your  \\\n",
       "0    0.000000  ...    0.0  0.0  0.0  0.0    0.0  0.053964  0.0  0.0   0.0   \n",
       "1    0.000000  ...    0.0  0.0  0.0  0.0    0.0  0.000000  0.0  0.0   0.0   \n",
       "2    0.000000  ...    0.0  0.0  0.0  0.0    0.0  0.058069  0.0  0.0   0.0   \n",
       "3    0.138491  ...    0.0  0.0  0.0  0.0    0.0  0.043132  0.0  0.0   0.0   \n",
       "4    0.000000  ...    0.0  0.0  0.0  0.0    0.0  0.096484  0.0  0.0   0.0   \n",
       "\n",
       "   zone  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vectors = vectorizer.fit_transform(dataset.Clean_text)\n",
    "words_dataset = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "words_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleksi fitur\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor,RegressorChain\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import SelectKBest,chi2 , f_regression, SelectFromModel, SelectPercentile\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf_vectorizer.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(dataset[['price','packaging','product','aroma']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3960, 10963), (3960, 4))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = MultiLabelBinarizer().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = SelectKBest(chi2, k=857).fit_transform(x, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 439)\t0.10022107864701454\n",
      "  (0, 788)\t0.11032370654189423\n",
      "  (0, 106)\t0.23742429129686818\n",
      "  (0, 792)\t0.12313365965772284\n",
      "  (0, 736)\t0.1121956449073298\n",
      "  (0, 169)\t0.14524491086503974\n",
      "  (0, 720)\t0.07224518263333046\n",
      "  (0, 849)\t0.11931974331632357\n",
      "  (0, 817)\t0.0961672866271731\n",
      "  (0, 339)\t0.11787321199888479\n",
      "  (0, 68)\t0.07447483468747404\n",
      "  (0, 665)\t0.1437151650176708\n",
      "  (0, 603)\t0.09946328576531863\n",
      "  (0, 783)\t0.19721485428737037\n",
      "  (0, 756)\t0.22362293480201823\n",
      "  (1, 672)\t0.15350429376134214\n",
      "  (1, 192)\t0.12586535255833364\n",
      "  (1, 310)\t0.1101064759247273\n",
      "  (1, 384)\t0.12586535255833364\n",
      "  (1, 370)\t0.16270963405818173\n",
      "  (1, 12)\t0.16270963405818173\n",
      "  (1, 426)\t0.16270963405818173\n",
      "  (1, 536)\t0.08423050023730182\n",
      "  (1, 143)\t0.11682916592385413\n",
      "  (1, 329)\t0.15015634635066596\n",
      "  :\t:\n",
      "  (3958, 614)\t0.08521944206378912\n",
      "  (3958, 707)\t0.16477898385145134\n",
      "  (3958, 675)\t0.17678866088244516\n",
      "  (3958, 688)\t0.11598608804067734\n",
      "  (3958, 692)\t0.08204936294451631\n",
      "  (3958, 446)\t0.10597090529957434\n",
      "  (3958, 439)\t0.09010120496609911\n",
      "  (3959, 140)\t0.38493634641437635\n",
      "  (3959, 187)\t0.18570393164870194\n",
      "  (3959, 289)\t0.14169242281064268\n",
      "  (3959, 76)\t0.1327695189665709\n",
      "  (3959, 645)\t0.13755672208482572\n",
      "  (3959, 256)\t0.2766554122203151\n",
      "  (3959, 659)\t0.14080503802230046\n",
      "  (3959, 543)\t0.1073541198686149\n",
      "  (3959, 18)\t0.16698445134271872\n",
      "  (3959, 13)\t0.09224018149025984\n",
      "  (3959, 44)\t0.09224018149025984\n",
      "  (3959, 152)\t0.07378167805579401\n",
      "  (3959, 614)\t0.0768424023732444\n",
      "  (3959, 707)\t0.07429063528889157\n",
      "  (3959, 835)\t0.07313608780829738\n",
      "  (3959, 767)\t0.07873953075091317\n",
      "  (3959, 336)\t0.042599532397367884\n",
      "  (3959, 536)\t0.15257520148741563\n"
     ]
    }
   ],
   "source": [
    "print(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_new_train, x_new_test, Y_train, Y_test = train_test_split(x_new,Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "## Fit the model on the training data.\n",
    "classifier = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "classifier.fit(x_new_train, Y_train)\n",
    "## See how the model performs on the test data.\n",
    "predictions = classifier.predict(x_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.838383838383834 %\n"
     ]
    }
   ],
   "source": [
    "knn_skor=classifier.score(x_new_test,np.array(Y_test))\n",
    "print(knn_skor * 100 ,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akurasi f1 score        : 83.2983193277311 %\n",
      "akurasi precision score : 98.50931677018635 %\n",
      "akurasi recall score    : 72.1565059144677 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import  multilabel_confusion_matrix\n",
    "\n",
    "multilabel = multilabel_confusion_matrix(Y_test,predictions)\n",
    "f1_score = metrics.f1_score(Y_test,predictions, average='micro', labels=np.unique(predictions))\n",
    "precision_score = metrics.precision_score(Y_test,predictions, average='micro', labels=np.unique(predictions))\n",
    "recall_score = metrics.recall_score(Y_test,predictions, average='micro', labels=np.unique(predictions))\n",
    "        \n",
    "print('akurasi f1 score        :', f1_score* 100 ,'%')\n",
    "print('akurasi precision score :', precision_score* 100 ,'%')\n",
    "print('akurasi recall score    :', recall_score* 100 ,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
