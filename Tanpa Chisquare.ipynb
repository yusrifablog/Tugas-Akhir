{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\yusrifa deta kirana\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\yusrifa deta kirana\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\yusrifa deta kirana\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\yusrifa deta kirana\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yusrifa deta kirana\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from nltk) (4.57.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\yusrifa deta kirana\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Sastrawi in c:\\users\\yusrifa deta kirana\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\yusrifa deta kirana\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans in c:\\users\\yusrifa deta kirana\\anaconda3\\lib\\site-packages\\googletrans-2.3.0-py3.7.egg (2.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yusrifa deta kirana\\anaconda3\\lib\\site-packages (from googletrans) (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yusrifa deta kirana\\anaconda3\\lib\\site-packages (from requests->googletrans) (2020.12.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\yusrifa deta kirana\\anaconda3\\lib\\site-packages (from requests->googletrans) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\yusrifa deta kirana\\anaconda3\\lib\\site-packages (from requests->googletrans) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\yusrifa deta kirana\\anaconda3\\lib\\site-packages (from requests->googletrans) (2.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Yusrifa Deta\n",
      "[nltk_data]     Kirana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Yusrifa Deta\n",
      "[nltk_data]     Kirana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "! pip3 install nltk\n",
    "! pip3 install Sastrawi\n",
    "! pip install googletrans\n",
    "\n",
    "# Import Library\n",
    "# text preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import requests\n",
    "import io\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import re # regular expression\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory # stemming indonesian language\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer # to create Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # tfid Vector \n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score # confussion matrix\n",
    "from sklearn.preprocessing import LabelEncoder # to convert classes to number \n",
    "from sklearn.model_selection import train_test_split  # for splitting data \n",
    "from sklearn.metrics import accuracy_score # to calculate accuracy\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'before_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>838</td>\n",
       "      <td>ini enak banget dipakainya, enteng banget diwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1166</td>\n",
       "      <td>the description is quite right. produk ini ema...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1421</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        review_text  price  \\\n",
       "0        708  sunscreen termahal yang pernah gue beli ini ka...     -1   \n",
       "1        838  ini enak banget dipakainya, enteng banget diwa...      0   \n",
       "2       1166  the description is quite right. produk ini ema...      0   \n",
       "3       1374  bisa untuk wajah dan badan dengan harga yang s...      1   \n",
       "4       1421  saya beli produk ini karena suka banget wangin...     -1   \n",
       "\n",
       "   packaging  product  aroma  \n",
       "0          0      1.0      0  \n",
       "1          0      1.0      0  \n",
       "2          0      1.0      1  \n",
       "3          1      1.0      0  \n",
       "4          0      0.0      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      0\n",
       "review_text    0\n",
       "price          0\n",
       "packaging      0\n",
       "product        1\n",
       "aroma          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      0\n",
       "review_text    0\n",
       "price          0\n",
       "packaging      0\n",
       "product        0\n",
       "aroma          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.fillna(method=\"ffill\")\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>838</td>\n",
       "      <td>ini enak banget dipakainya, enteng banget diwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1166</td>\n",
       "      <td>the description is quite right. produk ini ema...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1421</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        review_text  price  \\\n",
       "0        708  sunscreen termahal yang pernah gue beli ini ka...     -1   \n",
       "1        838  ini enak banget dipakainya, enteng banget diwa...      0   \n",
       "2       1166  the description is quite right. produk ini ema...      0   \n",
       "3       1374  bisa untuk wajah dan badan dengan harga yang s...      1   \n",
       "4       1421  saya beli produk ini karena suka banget wangin...     -1   \n",
       "\n",
       "   packaging  product  aroma  \n",
       "0          0      1.0      0  \n",
       "1          0      1.0      0  \n",
       "2          0      1.0      1  \n",
       "3          1      1.0      0  \n",
       "4          0      0.0      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casefolding \n",
    "\n",
    "def clean(dataset):\n",
    "  temp_text = []\n",
    "\n",
    "  for txt in dataset:\n",
    "    # removal of @name[mention]\n",
    "    txt = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", txt)\n",
    "\n",
    "    # removal of links[https://blabala.com]\n",
    "    # tw = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"\", tw)\n",
    "    txt = re.sub(r\"http\\S+\", \"\", txt)\n",
    "\n",
    "    # removal of new line\n",
    "    txt = re.sub('\\n', '', txt)\n",
    "\n",
    "    # removal of RT\n",
    "    txt = re.sub('RT', '', txt)\n",
    "\n",
    "    # removal of punctuations and numbers\n",
    "    txt = re.sub(\"[^a-zA-Z^']\", \" \", txt)\n",
    "    txt = re.sub(\" {2,}\", \" \", txt)\n",
    "\n",
    "    # remove leading and trailing whitespace\n",
    "    txt = txt.strip()\n",
    "\n",
    "    # remove whitespace with a single space\n",
    "    txt = re.sub(r'\\s+', ' ', txt)\n",
    "\n",
    "    # convert text to Lowercase\n",
    "    text = txt.lower();\n",
    "    temp_text.append(txt)\n",
    "  return temp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>838</td>\n",
       "      <td>ini enak banget dipakainya, enteng banget diwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ini enak banget dipakainya enteng banget diwaj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1166</td>\n",
       "      <td>the description is quite right. produk ini ema...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>the description is quite right produk ini eman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1421</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        review_text  price  \\\n",
       "0        708  sunscreen termahal yang pernah gue beli ini ka...     -1   \n",
       "1        838  ini enak banget dipakainya, enteng banget diwa...      0   \n",
       "2       1166  the description is quite right. produk ini ema...      0   \n",
       "3       1374  bisa untuk wajah dan badan dengan harga yang s...      1   \n",
       "4       1421  saya beli produk ini karena suka banget wangin...     -1   \n",
       "\n",
       "   packaging  product  aroma  \\\n",
       "0          0      1.0      0   \n",
       "1          0      1.0      0   \n",
       "2          0      1.0      1   \n",
       "3          1      1.0      0   \n",
       "4          0      0.0      1   \n",
       "\n",
       "                                               Clean  \n",
       "0  sunscreen termahal yang pernah gue beli ini ka...  \n",
       "1  ini enak banget dipakainya enteng banget diwaj...  \n",
       "2  the description is quite right produk ini eman...  \n",
       "3  bisa untuk wajah dan badan dengan harga yang s...  \n",
       "4  saya beli produk ini karena suka banget wangin...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Clean'] = clean(dataset['review_text'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOKENISASI\n",
    "def token(dataset):\n",
    "  return dataset.apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>sunscreen termahal yang pernah gue beli ini ka...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[sunscreen, termahal, yang, pernah, gue, beli,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>838</td>\n",
       "      <td>ini enak banget dipakainya, enteng banget diwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ini, enak, banget, dipakainya, enteng, banget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1166</td>\n",
       "      <td>the description is quite right. produk ini ema...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, description, is, quite, right, produk, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374</td>\n",
       "      <td>bisa untuk wajah dan badan dengan harga yang s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[bisa, untuk, wajah, dan, badan, dengan, harga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1421</td>\n",
       "      <td>saya beli produk ini karena suka banget wangin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[saya, beli, produk, ini, karena, suka, banget...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        review_text  price  \\\n",
       "0        708  sunscreen termahal yang pernah gue beli ini ka...     -1   \n",
       "1        838  ini enak banget dipakainya, enteng banget diwa...      0   \n",
       "2       1166  the description is quite right. produk ini ema...      0   \n",
       "3       1374  bisa untuk wajah dan badan dengan harga yang s...      1   \n",
       "4       1421  saya beli produk ini karena suka banget wangin...     -1   \n",
       "\n",
       "   packaging  product  aroma  \\\n",
       "0          0      1.0      0   \n",
       "1          0      1.0      0   \n",
       "2          0      1.0      1   \n",
       "3          1      1.0      0   \n",
       "4          0      0.0      1   \n",
       "\n",
       "                                               Clean  \n",
       "0  [sunscreen, termahal, yang, pernah, gue, beli,...  \n",
       "1  [ini, enak, banget, dipakainya, enteng, banget...  \n",
       "2  [the, description, is, quite, right, produk, i...  \n",
       "3  [bisa, untuk, wajah, dan, badan, dengan, harga...  \n",
       "4  [saya, beli, produk, ini, karena, suka, banget...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Clean'] = token(dataset['Clean'])\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def stop_words(dataset) :\n",
    " # stop_words = set(stopwords.words('indonesian'))\n",
    " # return dataset.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "#dataset['Clean'] = stop_words(dataset['Clean'])\n",
    "#dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer, CountVectorizer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_vectorize = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.49248889, 0.        , 0.40264194, 0.77157901,\n",
       "        0.        ],\n",
       "       [0.77157901, 0.49248889, 0.        , 0.40264194, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.49248889, 0.        , 0.40264194, 0.        ,\n",
       "        0.77157901],\n",
       "       [0.        , 0.        , 0.88654763, 0.46263733, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'Pusing satu kali',\n",
    "    'Pusing dua kali',\n",
    "    'Pusing tiga kali',\n",
    "    'Pusing lagi']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# contoh\n",
    "a = vectorizer.fit_transform(corpus)\n",
    "a.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3960, 11919)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dataset['review_text']\n",
    "# Count TF_IDF Vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vector = count_vectorizer.fit_transform(dataset['review_text'])\n",
    "count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10508)\t0.21755947863811115\n",
      "  (0, 10910)\t0.1918674438131206\n",
      "  (0, 11845)\t0.04627303732722482\n",
      "  (0, 8536)\t0.09692855006425057\n",
      "  (0, 4104)\t0.29197011723583527\n",
      "  (0, 1146)\t0.0725581512259172\n",
      "  (0, 4640)\t0.10104005098570525\n",
      "  (0, 5090)\t0.13978095002176325\n",
      "  (0, 1855)\t0.11656957507439628\n",
      "  (0, 4717)\t0.18071324567985922\n",
      "  (0, 11792)\t0.11608443100934708\n",
      "  (0, 10065)\t0.07028628025894527\n",
      "  (0, 614)\t0.10551113714137114\n",
      "  (0, 11744)\t0.13289626263283422\n",
      "  (0, 2493)\t0.1413066468813367\n",
      "  (0, 1868)\t0.1533423673625266\n",
      "  (0, 417)\t0.1700491709924254\n",
      "  (0, 10478)\t0.17890012247991563\n",
      "  (0, 9363)\t0.06437169788817153\n",
      "  (0, 10502)\t0.18960875722150158\n",
      "  (0, 4369)\t0.17890012247991563\n",
      "  (0, 10304)\t0.10965967531992081\n",
      "  (0, 7670)\t0.1871194898606684\n",
      "  (0, 6891)\t0.14890682313598788\n",
      "  (0, 11722)\t0.13065996280800182\n",
      "  :\t:\n",
      "  (3959, 2329)\t0.09800820655599626\n",
      "  (3959, 9007)\t0.10589448419949808\n",
      "  (3959, 1717)\t0.11420943446195812\n",
      "  (3959, 9382)\t0.13581543808084823\n",
      "  (3959, 7898)\t0.09588989617557801\n",
      "  (3959, 5510)\t0.15618048162657658\n",
      "  (3959, 3893)\t0.2699812618375596\n",
      "  (3959, 9206)\t0.13268223021932796\n",
      "  (3959, 1216)\t0.12806466753961188\n",
      "  (3959, 2726)\t0.16992745818689195\n",
      "  (3959, 5664)\t0.12229871423242585\n",
      "  (3959, 1850)\t0.17406245591004813\n",
      "  (3959, 4404)\t0.14501126400691408\n",
      "  (3959, 668)\t0.12690135114831208\n",
      "  (3959, 7309)\t0.1791232841129578\n",
      "  (3959, 2149)\t0.14768254760513377\n",
      "  (3959, 878)\t0.17406245591004813\n",
      "  (3959, 5848)\t0.18564782644080396\n",
      "  (3959, 11144)\t0.05726615696765328\n",
      "  (3959, 4341)\t0.13667137729628945\n",
      "  (3959, 2774)\t0.1791232841129578\n",
      "  (3959, 1980)\t0.37129565288160793\n",
      "  (3959, 8819)\t0.18564782644080396\n",
      "  (3959, 6899)\t0.1948436523668698\n",
      "  (3959, 1780)\t0.1948436523668698\n"
     ]
    }
   ],
   "source": [
    "a = dataset['review_text']\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer = tfidf_vectorizer.fit_transform(a)\n",
    "print(tfidf_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3960, 11919)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf_vectorizer.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(dataset[['price','packaging','product','aroma']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1.]\n",
      " ...\n",
      " [ 0.  0. -1. -1.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0. -1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3960, 11919), (3960, 4))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "Y = MultiLabelBinarizer().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(x,Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2772, 11919), (1188, 11919))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "## Fit the model on the training data.\n",
    "classifier = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "classifier.fit(x_train, Y_train)\n",
    "## See how the model performs on the test data.\n",
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.07070707070707 %\n"
     ]
    }
   ],
   "source": [
    "knn_skor=classifier.score(x_test,np.array(Y_test))\n",
    "print(knn_skor * 100 ,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akurasi f1 score        : 86.42506142506143 %\n",
      "akurasi precision score : 87.9375 %\n",
      "akurasi recall score    : 84.96376811594203 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import  multilabel_confusion_matrix\n",
    "\n",
    "multilabel = multilabel_confusion_matrix(Y_test,predictions)\n",
    "f1_score = metrics.f1_score(Y_test,predictions, average='micro', labels=np.unique(predictions))\n",
    "precision_score = metrics.precision_score(Y_test,predictions, average='micro', labels=np.unique(predictions))\n",
    "recall_score = metrics.recall_score(Y_test,predictions, average='micro', labels=np.unique(predictions))\n",
    "        \n",
    "print('akurasi f1 score        :', f1_score* 100 ,'%')\n",
    "print('akurasi precision score :', precision_score* 100 ,'%')\n",
    "print('akurasi recall score    :', recall_score* 100 ,'%')\n",
    "#print (multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 527  175]\n",
      "  [ 248  238]]\n",
      "\n",
      " [[   0   18]\n",
      "  [   1 1169]]\n",
      "\n",
      " [[  39  179]\n",
      "  [  51  919]]]\n"
     ]
    }
   ],
   "source": [
    "# classification_report\n",
    "#multilabel = multilabel_confusion_matrix(Y_test,predictions)\n",
    "print(multilabel_confusion_matrix(Y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
