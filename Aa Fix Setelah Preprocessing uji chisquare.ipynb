{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data_train_lengkap.csv', sep=';')\n",
    "data_test = pd.read_csv('data_test_lengkap.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dair penasaran banget skincare reviewnya banya...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ngincer bilang dupenya ski baca review tertawa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suka tabirsurya tekstur ringan serap banget ku...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nyobain pas muka lagi stress ny desperate bang...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suka gokujyun losion merek hada labo lotionnya...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  price  packaging  \\\n",
       "0  dair penasaran banget skincare reviewnya banya...     -1          0   \n",
       "1  ngincer bilang dupenya ski baca review tertawa...      0          0   \n",
       "2  suka tabirsurya tekstur ringan serap banget ku...      0          1   \n",
       "3  nyobain pas muka lagi stress ny desperate bang...      0          0   \n",
       "4  suka gokujyun losion merek hada labo lotionnya...      1          0   \n",
       "\n",
       "   product  aroma  \n",
       "0      0.0      0  \n",
       "1      1.0      0  \n",
       "2      1.0      0  \n",
       "3     -1.0      0  \n",
       "4      1.0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>price</th>\n",
       "      <th>packaging</th>\n",
       "      <th>product</th>\n",
       "      <th>aroma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>produk favorit banget enak dipake plus tidak r...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lengket pas dipake hitungan tabirsurya yang ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minyak kontrol lumayan ngempesin jerawat efek ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>favorite banget harga terjangkau banget gak ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exfoliant toner pakai bagi step double toning ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  price  packaging  \\\n",
       "0  produk favorit banget enak dipake plus tidak r...     -1          0   \n",
       "1  lengket pas dipake hitungan tabirsurya yang ti...      1          0   \n",
       "2  minyak kontrol lumayan ngempesin jerawat efek ...      1          0   \n",
       "3  favorite banget harga terjangkau banget gak ha...      1          0   \n",
       "4  exfoliant toner pakai bagi step double toning ...      0          0   \n",
       "\n",
       "   product  aroma  \n",
       "0      1.0      0  \n",
       "1      0.0      0  \n",
       "2     -1.0      0  \n",
       "3      1.0      0  \n",
       "4      1.0      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_text    0\n",
       "price          0\n",
       "packaging      0\n",
       "product        0\n",
       "aroma          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_text    0\n",
       "price          0\n",
       "packaging      0\n",
       "product        0\n",
       "aroma          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train['review_text']\n",
    "X_test = data_test['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "fitur_train = TfidfVectorizer().fit(X_train)\n",
    "tfidf_train = fitur_train.transform(X_train).toarray()\n",
    "tfidf_test = fitur_train.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitur_tfidf(tfidf, fitur):\n",
    "    terms = tfidf.get_feature_names()\n",
    "    sums = fitur.sum(axis = 0)\n",
    "\n",
    "    data = []\n",
    "    for col, term in enumerate(terms):\n",
    "        data.append((term, sums[col] ))\n",
    "    ranking = pd.DataFrame(data, columns=['Terms','TF-IDF'])\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tfidf_tr = get_fitur_tfidf(fitur_train, tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7361, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tfidf_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SELECTION CHI SQUARE\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chi_tr = tfidf_train\n",
    "x_chi_test = tfidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_chi_tr = np.array(data_train[['price','packaging','aroma','product']])\n",
    "#y_chi_test = np.array(data_test[['price','packaging','aroma','product']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_price_tr = (data_train['price'])\n",
    "y_packaging_tr = (data_train['packaging'])\n",
    "y_product_tr = (data_train['product'])\n",
    "y_aroma_tr = (data_train['aroma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_price_test = (data_test['price'])\n",
    "y_packaging_test = (data_test['packaging'])\n",
    "y_product_test = (data_test['product'])\n",
    "y_aroma_test = (data_test['aroma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_price_tr_all = SelectKBest(score_func=chi2, k='all').fit_transform(x_chi_tr, y_price_tr)\n",
    "chi_packaging_tr_all = SelectKBest(score_func=chi2, k='all').fit_transform(x_chi_tr, y_packaging_tr)\n",
    "chi_product_tr_all = SelectKBest(score_func=chi2, k='all').fit_transform(x_chi_tr, y_product_tr)\n",
    "chi_aroma_tr_all = SelectKBest(score_func=chi2, k='all').fit_transform(x_chi_tr, y_aroma_tr)\n",
    "\n",
    "chi_price_tr_5633 = SelectKBest(score_func=chi2, k=5521).fit_transform(x_chi_tr, y_price_tr)\n",
    "chi_packaging_tr_5633 = SelectKBest(score_func=chi2, k=5521).fit_transform(x_chi_tr, y_packaging_tr)\n",
    "chi_product_tr_5633 = SelectKBest(score_func=chi2, k=5521).fit_transform(x_chi_tr, y_product_tr)\n",
    "chi_aroma_tr_5633 = SelectKBest(score_func=chi2, k=5521).fit_transform(x_chi_tr, y_aroma_tr)\n",
    "\n",
    "chi_price_tr_3755 = SelectKBest(score_func=chi2, k=3680).fit_transform(x_chi_tr, y_price_tr)\n",
    "chi_packaging_tr_3755 = SelectKBest(score_func=chi2, k=3680).fit_transform(x_chi_tr, y_packaging_tr)\n",
    "chi_product_tr_3755 = SelectKBest(score_func=chi2, k=3680).fit_transform(x_chi_tr, y_product_tr)\n",
    "chi_aroma_tr_3755 = SelectKBest(score_func=chi2, k=3680).fit_transform(x_chi_tr, y_aroma_tr)\n",
    "\n",
    "chi_price_tr_2253 = SelectKBest(score_func=chi2, k=2208).fit_transform(x_chi_tr, y_price_tr)\n",
    "chi_packaging_tr_2253 = SelectKBest(score_func=chi2, k=2208).fit_transform(x_chi_tr, y_packaging_tr)\n",
    "chi_product_tr_2253 = SelectKBest(score_func=chi2, k=2208).fit_transform(x_chi_tr, y_product_tr)\n",
    "chi_aroma_tr_2253 = SelectKBest(score_func=chi2, k=2208).fit_transform(x_chi_tr, y_aroma_tr)\n",
    "\n",
    "chi_price_tr_376 = SelectKBest(score_func=chi2, k=368).fit_transform(x_chi_tr, y_price_tr)\n",
    "chi_packaging_tr_376 = SelectKBest(score_func=chi2, k=368).fit_transform(x_chi_tr, y_packaging_tr)\n",
    "chi_product_tr_376 = SelectKBest(score_func=chi2, k=368).fit_transform(x_chi_tr, y_product_tr)\n",
    "chi_aroma_tr_376 = SelectKBest(score_func=chi2, k=368).fit_transform(x_chi_tr, y_aroma_tr)\n",
    "\n",
    "chi_price_tr_76 = SelectKBest(score_func=chi2, k=74).fit_transform(x_chi_tr, y_price_tr)\n",
    "chi_packaging_tr_76 = SelectKBest(score_func=chi2, k=74).fit_transform(x_chi_tr, y_packaging_tr)\n",
    "chi_product_tr_76 = SelectKBest(score_func=chi2, k=74).fit_transform(x_chi_tr, y_product_tr)\n",
    "chi_aroma_tr_76 = SelectKBest(score_func=chi2, k=74).fit_transform(x_chi_tr, y_aroma_tr)\n",
    "\n",
    "chi_price_tr_30 = SelectKBest(score_func=chi2, k=30).fit_transform(x_chi_tr, y_price_tr)\n",
    "chi_packaging_tr_30 = SelectKBest(score_func=chi2, k=30).fit_transform(x_chi_tr, y_packaging_tr)\n",
    "chi_product_tr_30 = SelectKBest(score_func=chi2, k=30).fit_transform(x_chi_tr, y_product_tr)\n",
    "chi_aroma_tr_30 = SelectKBest(score_func=chi2, k=30).fit_transform(x_chi_tr, y_aroma_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_price_test_all = SelectKBest(score_func=chi2, k='all').fit_transform(x_chi_test, y_price_test)\n",
    "chi_packaging_test_all = SelectKBest(score_func=chi2, k='all').fit_transform(x_chi_test, y_packaging_test)\n",
    "chi_product_test_all = SelectKBest(score_func=chi2, k='all').fit_transform(x_chi_test, y_product_test)\n",
    "chi_aroma_test_all = SelectKBest(score_func=chi2, k='all').fit_transform(x_chi_test, y_aroma_test)\n",
    "\n",
    "chi_price_test_5633 = SelectKBest(score_func=chi2, k=5521).fit_transform(x_chi_test, y_price_test)\n",
    "chi_packaging_test_5633 = SelectKBest(score_func=chi2, k=5521).fit_transform(x_chi_test, y_packaging_test)\n",
    "chi_product_test_5633 = SelectKBest(score_func=chi2, k=5521).fit_transform(x_chi_test, y_product_test)\n",
    "chi_aroma_test_5633 = SelectKBest(score_func=chi2, k=5521).fit_transform(x_chi_test, y_aroma_test)\n",
    "\n",
    "chi_price_test_3755 = SelectKBest(score_func=chi2, k=3680).fit_transform(x_chi_test, y_price_test)\n",
    "chi_packaging_test_3755 = SelectKBest(score_func=chi2, k=3680).fit_transform(x_chi_test, y_packaging_test)\n",
    "chi_product_test_3755 = SelectKBest(score_func=chi2, k=3680).fit_transform(x_chi_test, y_product_test)\n",
    "chi_aroma_test_3755 = SelectKBest(score_func=chi2, k=3680).fit_transform(x_chi_test, y_aroma_test)\n",
    "\n",
    "chi_price_test_2253 = SelectKBest(score_func=chi2, k=2208).fit_transform(x_chi_test, y_price_test)\n",
    "chi_packaging_test_2253 = SelectKBest(score_func=chi2, k=2208).fit_transform(x_chi_test, y_packaging_test)\n",
    "chi_product_test_2253 = SelectKBest(score_func=chi2, k=2208).fit_transform(x_chi_test, y_product_test)\n",
    "chi_aroma_test_2253 = SelectKBest(score_func=chi2, k=2208).fit_transform(x_chi_test, y_aroma_test)\n",
    "\n",
    "chi_price_test_376 = SelectKBest(score_func=chi2, k=368).fit_transform(x_chi_test, y_price_test)\n",
    "chi_packaging_test_376 = SelectKBest(score_func=chi2, k=368).fit_transform(x_chi_test, y_packaging_test)\n",
    "chi_product_test_376 = SelectKBest(score_func=chi2, k=368).fit_transform(x_chi_test, y_product_test)\n",
    "chi_aroma_test_376 = SelectKBest(score_func=chi2, k=368).fit_transform(x_chi_test, y_aroma_test)\n",
    "\n",
    "chi_price_test_76 = SelectKBest(score_func=chi2, k=74).fit_transform(x_chi_test, y_price_test)\n",
    "chi_packaging_test_76 = SelectKBest(score_func=chi2, k=74).fit_transform(x_chi_test, y_packaging_test)\n",
    "chi_product_test_76 = SelectKBest(score_func=chi2, k=74).fit_transform(x_chi_test, y_product_test)\n",
    "chi_aroma_test_76 = SelectKBest(score_func=chi2, k=74).fit_transform(x_chi_test, y_aroma_test)\n",
    "\n",
    "chi_price_test_30 = SelectKBest(score_func=chi2, k=30).fit_transform(x_chi_test, y_price_test)\n",
    "chi_packaging_test_30 = SelectKBest(score_func=chi2, k=30).fit_transform(x_chi_test, y_packaging_test)\n",
    "chi_product_test_30 = SelectKBest(score_func=chi2, k=30).fit_transform(x_chi_test, y_product_test)\n",
    "chi_aroma_test_30 = SelectKBest(score_func=chi2, k=30).fit_transform(x_chi_test, y_aroma_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#aspek price\n",
    "knn_price_all = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_price_5633 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_price_3755 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_price_2253 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_price_376 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_price_76 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_price_30 = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "knn_price_all.fit(chi_price_tr_all, y_price_tr)\n",
    "knn_price_5633.fit(chi_price_tr_5633, y_price_tr)\n",
    "knn_price_3755.fit(chi_price_tr_3755, y_price_tr)\n",
    "knn_price_2253.fit(chi_price_tr_2253, y_price_tr)\n",
    "knn_price_376.fit(chi_price_tr_376, y_price_tr)\n",
    "knn_price_76.fit(chi_price_tr_76, y_price_tr)\n",
    "knn_price_30.fit(chi_price_tr_30, y_price_tr)\n",
    "\n",
    "predictions_price_all = knn_price_all.predict(chi_price_test_all)\n",
    "predictions_price_5633 = knn_price_5633.predict(chi_price_test_5633)\n",
    "predictions_price_3755 = knn_price_3755.predict(chi_price_test_3755)\n",
    "predictions_price_2253 = knn_price_2253.predict(chi_price_test_2253)\n",
    "predictions_price_376 = knn_price_376.predict(chi_price_test_376)\n",
    "predictions_price_76 = knn_price_76.predict(chi_price_test_76)\n",
    "predictions_price_30 = knn_price_30.predict(chi_price_test_30)\n",
    "\n",
    "#aspek packaging\n",
    "knn_packaging_all = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_packaging_5633 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_packaging_3755 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_packaging_2253 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_packaging_376 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_packaging_76 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_packaging_30 = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "knn_packaging_all.fit(chi_packaging_tr_all, y_packaging_tr)\n",
    "knn_packaging_5633.fit(chi_packaging_tr_5633, y_packaging_tr)\n",
    "knn_packaging_3755.fit(chi_packaging_tr_3755, y_packaging_tr)\n",
    "knn_packaging_2253.fit(chi_packaging_tr_2253, y_packaging_tr)\n",
    "knn_packaging_376.fit(chi_packaging_tr_376, y_packaging_tr)\n",
    "knn_packaging_76.fit(chi_packaging_tr_76, y_packaging_tr)\n",
    "knn_packaging_30.fit(chi_packaging_tr_30, y_packaging_tr)\n",
    "\n",
    "predictions_packaging_all = knn_packaging_all.predict(chi_packaging_test_all)\n",
    "predictions_packaging_5633 = knn_packaging_5633.predict(chi_packaging_test_5633)\n",
    "predictions_packaging_3755 = knn_packaging_3755.predict(chi_packaging_test_3755)\n",
    "predictions_packaging_2253 = knn_packaging_2253.predict(chi_packaging_test_2253)\n",
    "predictions_packaging_376 = knn_packaging_376.predict(chi_packaging_test_376)\n",
    "predictions_packaging_76 = knn_packaging_76.predict(chi_packaging_test_76)\n",
    "predictions_packaging_30 = knn_packaging_30.predict(chi_packaging_test_30)\n",
    "\n",
    "#aspek product\n",
    "knn_product_all = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_product_5633 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_product_3755 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_product_2253 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_product_376 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_product_76 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_product_30 = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "knn_product_all.fit(chi_product_tr_all, y_product_tr)\n",
    "knn_product_5633.fit(chi_product_tr_5633, y_product_tr)\n",
    "knn_product_3755.fit(chi_product_tr_3755, y_product_tr)\n",
    "knn_product_2253.fit(chi_product_tr_2253, y_product_tr)\n",
    "knn_product_376.fit(chi_product_tr_376, y_product_tr)\n",
    "knn_product_76.fit(chi_product_tr_76, y_product_tr)\n",
    "knn_product_30.fit(chi_product_tr_30, y_product_tr)\n",
    "\n",
    "predictions_product_all = knn_product_all.predict(chi_product_test_all)\n",
    "predictions_product_5633 = knn_product_5633.predict(chi_product_test_5633)\n",
    "predictions_product_3755 = knn_product_3755.predict(chi_product_test_3755)\n",
    "predictions_product_2253 = knn_product_2253.predict(chi_product_test_2253)\n",
    "predictions_product_376 = knn_product_376.predict(chi_product_test_376)\n",
    "predictions_product_76 = knn_product_76.predict(chi_product_test_76)\n",
    "predictions_product_30 = knn_product_30.predict(chi_product_test_30)\n",
    "\n",
    "#aspek aroma\n",
    "knn_aroma_all = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_aroma_5633 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_aroma_3755 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_aroma_2253 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_aroma_376 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_aroma_76 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_aroma_30 = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "knn_aroma_all.fit(chi_aroma_tr_all, y_aroma_tr)\n",
    "knn_aroma_5633.fit(chi_aroma_tr_5633, y_aroma_tr)\n",
    "knn_aroma_3755.fit(chi_aroma_tr_3755, y_aroma_tr)\n",
    "knn_aroma_2253.fit(chi_aroma_tr_2253, y_aroma_tr)\n",
    "knn_aroma_376.fit(chi_aroma_tr_376, y_aroma_tr)\n",
    "knn_aroma_76.fit(chi_aroma_tr_76, y_aroma_tr)\n",
    "knn_aroma_30.fit(chi_aroma_tr_30, y_aroma_tr)\n",
    "\n",
    "predictions_aroma_all = knn_aroma_all.predict(chi_aroma_test_all)\n",
    "predictions_aroma_5633 = knn_aroma_5633.predict(chi_aroma_test_5633)\n",
    "predictions_aroma_3755 = knn_aroma_3755.predict(chi_aroma_test_3755)\n",
    "predictions_aroma_2253 = knn_aroma_2253.predict(chi_aroma_test_2253)\n",
    "predictions_aroma_376 = knn_aroma_376.predict(chi_aroma_test_376)\n",
    "predictions_aroma_76 = knn_aroma_76.predict(chi_aroma_test_76)\n",
    "predictions_aroma_30 = knn_aroma_30.predict(chi_aroma_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== PRICE ===================\n",
      "Nilai Model price K-NN pada K-50 tanpa seleksi                      : 66.66666666666666 %\n",
      "Nilai Model price K-NN pada K-50  dengan fitur seleksi 5633         : 52.90404040404041 %\n",
      "Nilai Model price K-NN pada K-50  dengan fitur seleksi 3755         : 52.90404040404041 %\n",
      "Nilai Model price K-NN pada K-50  dengan fitur seleksi 2253         : 52.90404040404041 %\n",
      "Nilai Model price K-NN pada K-50  dengan fitur seleksi 376          : 52.90404040404041 %\n",
      "Nilai Model price K-NN pada K-50  dengan fitur seleksi 76           : 53.40909090909091 %\n",
      "Nilai Model price K-NN pada K-50  dengan fitur seleksi 30           : 49.24242424242424 %\n",
      "                                                                             \n",
      "============= PACKAGING ================\n",
      "Nilai Model packaging K-NN pada K-50 tanpa seleksi                      : 84.84848484848484 %\n",
      "Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 5633         : 84.84848484848484 %\n",
      "Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 3755         : 84.84848484848484 %\n",
      "Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 2253         : 84.84848484848484 %\n",
      "Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 376          : 84.72222222222221 %\n",
      "Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 76           : 84.97474747474747 %\n",
      "Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 30           : 84.46969696969697 %\n",
      "                                                                             \n",
      "============= PRODUCT ================\n",
      "Nilai Model product K-NN pada K-50 tanpa seleksi                      : 71.33838383838383 %\n",
      "Nilai Model product K-NN pada K-50  dengan fitur seleksi 5633         : 67.67676767676768 %\n",
      "Nilai Model product K-NN pada K-50  dengan fitur seleksi 3755         : 67.67676767676768 %\n",
      "Nilai Model product K-NN pada K-50  dengan fitur seleksi 2253         : 67.67676767676768 %\n",
      "Nilai Model product K-NN pada K-50  dengan fitur seleksi 376          : 67.67676767676768 %\n",
      "Nilai Model product K-NN pada K-50  dengan fitur seleksi 76           : 67.8030303030303 %\n",
      "Nilai Model product K-NN pada K-50  dengan fitur seleksi 30           : 68.68686868686868 %\n",
      "                                                                             \n",
      "============= AROMA ================\n",
      "Nilai Model aroma K-NN pada K-50 tanpa seleksi                      : 79.67171717171718 %\n",
      "Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 5633         : 77.65151515151516 %\n",
      "Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 3755         : 77.65151515151516 %\n",
      "Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 2253         : 77.65151515151516 %\n",
      "Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 376          : 77.77777777777779 %\n",
      "Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 76           : 79.41919191919192 %\n",
      "Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 30           : 76.64141414141415 %\n"
     ]
    }
   ],
   "source": [
    "#Nilai price\n",
    "knn_all_price_skor=knn_price_all.score(chi_price_test_all,y_price_test)\n",
    "knn_5633_price_skor=knn_price_5633.score(chi_price_test_5633,y_price_test)\n",
    "knn_3755_price_skor=knn_price_3755.score(chi_price_test_3755,y_price_test)\n",
    "knn_2253_price_skor=knn_price_2253.score(chi_price_test_2253,y_price_test)\n",
    "knn_376_price_skor=knn_price_376.score(chi_price_test_376,y_price_test)\n",
    "knn_76_price_skor=knn_price_76.score(chi_price_test_76,y_price_test)\n",
    "knn_30_price_skor=knn_price_30.score(chi_price_test_30,y_price_test)\n",
    "#nilai packaging\n",
    "\n",
    "knn_all_packaging_skor=knn_packaging_all.score(chi_packaging_test_all,y_packaging_test)\n",
    "knn_5633_packaging_skor=knn_packaging_5633.score(chi_packaging_test_5633,y_packaging_test)\n",
    "knn_3755_packaging_skor=knn_packaging_3755.score(chi_packaging_test_3755,y_packaging_test)\n",
    "knn_2253_packaging_skor=knn_packaging_2253.score(chi_packaging_test_2253,y_packaging_test)\n",
    "knn_376_packaging_skor=knn_packaging_376.score(chi_packaging_test_376,y_packaging_test)\n",
    "knn_76_packaging_skor=knn_packaging_76.score(chi_packaging_test_76,y_packaging_test)\n",
    "knn_30_packaging_skor=knn_packaging_30.score(chi_packaging_test_30,y_packaging_test)\n",
    "#nilai product\n",
    "\n",
    "knn_all_product_skor=knn_product_all.score(chi_product_test_all,y_product_test)\n",
    "knn_5633_product_skor=knn_product_5633.score(chi_product_test_5633,y_product_test)\n",
    "knn_3755_product_skor=knn_product_3755.score(chi_product_test_3755,y_product_test)\n",
    "knn_2253_product_skor=knn_product_2253.score(chi_product_test_2253,y_product_test)\n",
    "knn_376_product_skor=knn_product_376.score(chi_product_test_376,y_product_test)\n",
    "knn_76_product_skor=knn_product_76.score(chi_product_test_76,y_product_test)\n",
    "knn_30_product_skor=knn_product_30.score(chi_product_test_30,y_product_test)\n",
    "#nilai aroma\n",
    "\n",
    "knn_all_aroma_skor=knn_aroma_all.score(chi_aroma_test_all,y_aroma_test)\n",
    "knn_5633_aroma_skor=knn_aroma_5633.score(chi_aroma_test_5633,y_aroma_test)\n",
    "knn_3755_aroma_skor=knn_aroma_3755.score(chi_aroma_test_3755,y_aroma_test)\n",
    "knn_2253_aroma_skor=knn_aroma_2253.score(chi_aroma_test_2253,y_aroma_test)\n",
    "knn_376_aroma_skor=knn_aroma_376.score(chi_aroma_test_376,y_aroma_test)\n",
    "knn_76_aroma_skor=knn_aroma_76.score(chi_aroma_test_76,y_aroma_test)\n",
    "knn_30_aroma_skor=knn_aroma_30.score(chi_aroma_test_30,y_aroma_test)\n",
    "\n",
    "print('=============== PRICE ===================')\n",
    "print('Nilai Model price K-NN pada K-50 tanpa seleksi                      :',knn_all_price_skor * 100 ,'%')\n",
    "print('Nilai Model price K-NN pada K-50  dengan fitur seleksi 5633         :',knn_5633_price_skor * 100 ,'%')\n",
    "print('Nilai Model price K-NN pada K-50  dengan fitur seleksi 3755         :',knn_3755_price_skor * 100 ,'%')\n",
    "print('Nilai Model price K-NN pada K-50  dengan fitur seleksi 2253         :',knn_2253_price_skor * 100 ,'%')\n",
    "print('Nilai Model price K-NN pada K-50  dengan fitur seleksi 376          :',knn_376_price_skor * 100 ,'%')\n",
    "print('Nilai Model price K-NN pada K-50  dengan fitur seleksi 76           :',knn_76_price_skor * 100 ,'%')\n",
    "print('Nilai Model price K-NN pada K-50  dengan fitur seleksi 30           :',knn_30_price_skor * 100 ,'%')\n",
    "print('                                                                             ')\n",
    "print('============= PACKAGING ================')\n",
    "print('Nilai Model packaging K-NN pada K-50 tanpa seleksi                      :',knn_all_packaging_skor * 100 ,'%')\n",
    "print('Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 5633         :',knn_5633_packaging_skor * 100 ,'%')\n",
    "print('Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 3755         :',knn_3755_packaging_skor * 100 ,'%')\n",
    "print('Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 2253         :',knn_2253_packaging_skor * 100 ,'%')\n",
    "print('Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 376          :',knn_376_packaging_skor * 100 ,'%')\n",
    "print('Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 76           :',knn_76_packaging_skor * 100 ,'%')\n",
    "print('Nilai Model packaging K-NN pada K-50  dengan fitur seleksi 30           :',knn_30_packaging_skor * 100 ,'%')\n",
    "print('                                                                             ')\n",
    "print('============= PRODUCT ================')\n",
    "print('Nilai Model product K-NN pada K-50 tanpa seleksi                      :',knn_all_product_skor * 100 ,'%')\n",
    "print('Nilai Model product K-NN pada K-50  dengan fitur seleksi 5633         :',knn_5633_product_skor * 100 ,'%')\n",
    "print('Nilai Model product K-NN pada K-50  dengan fitur seleksi 3755         :',knn_3755_product_skor * 100 ,'%')\n",
    "print('Nilai Model product K-NN pada K-50  dengan fitur seleksi 2253         :',knn_2253_product_skor * 100 ,'%')\n",
    "print('Nilai Model product K-NN pada K-50  dengan fitur seleksi 376          :',knn_376_product_skor * 100 ,'%')\n",
    "print('Nilai Model product K-NN pada K-50  dengan fitur seleksi 76           :',knn_76_product_skor * 100 ,'%')\n",
    "print('Nilai Model product K-NN pada K-50  dengan fitur seleksi 30           :',knn_30_product_skor * 100 ,'%')\n",
    "print('                                                                             ')\n",
    "print('============= AROMA ================')\n",
    "print('Nilai Model aroma K-NN pada K-50 tanpa seleksi                      :',knn_all_aroma_skor * 100 ,'%')\n",
    "print('Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 5633         :',knn_5633_aroma_skor * 100 ,'%')\n",
    "print('Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 3755         :',knn_3755_aroma_skor * 100 ,'%')\n",
    "print('Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 2253         :',knn_2253_aroma_skor * 100 ,'%')\n",
    "print('Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 376          :',knn_376_aroma_skor * 100 ,'%')\n",
    "print('Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 76           :',knn_76_aroma_skor * 100 ,'%')\n",
    "print('Nilai Model aroma K-NN pada K-50  dengan fitur seleksi 30           :',knn_30_aroma_skor * 100 ,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "#from sklearn.metrics import  multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[ 20 112  20]\n",
      " [  3 383  33]\n",
      " [  1  95 125]]\n",
      "\n",
      "Accuracy: 0.67\n",
      "\n",
      "Micro Precision: 0.67\n",
      "Micro Recall: 0.67\n",
      "Micro F1-score: 0.67\n",
      "\n",
      "Macro Precision: 0.73\n",
      "Macro Recall: 0.54\n",
      "Macro F1-score: 0.54\n",
      "\n",
      "Weighted Precision: 0.70\n",
      "Weighted Recall: 0.67\n",
      "Weighted F1-score: 0.62\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.13      0.23       152\n",
      "           0       0.65      0.91      0.76       419\n",
      "           1       0.70      0.57      0.63       221\n",
      "\n",
      "    accuracy                           0.67       792\n",
      "   macro avg       0.73      0.54      0.54       792\n",
      "weighted avg       0.70      0.67      0.62       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Price Pada K = 7 tanpa seleksi\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_price_test,predictions_price_all)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_price_test,predictions_price_all)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_all, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_all, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_all, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_all, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_all, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_all, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_all, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_all, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_price_test,predictions_price_all, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_price_test,predictions_price_all, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0 152   0]\n",
      " [  0 419   0]\n",
      " [  0 221   0]]\n",
      "\n",
      "Accuracy: 0.53\n",
      "\n",
      "Micro Precision: 0.53\n",
      "Micro Recall: 0.53\n",
      "Micro F1-score: 0.53\n",
      "\n",
      "Macro Precision: 0.18\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.23\n",
      "\n",
      "Weighted Precision: 0.28\n",
      "Weighted Recall: 0.53\n",
      "Weighted F1-score: 0.37\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       152\n",
      "           0       0.53      1.00      0.69       419\n",
      "           1       0.00      0.00      0.00       221\n",
      "\n",
      "    accuracy                           0.53       792\n",
      "   macro avg       0.18      0.33      0.23       792\n",
      "weighted avg       0.28      0.53      0.37       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Price Pada K = 7 dengan fitur seleksi 5633\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_price_test,predictions_price_5633)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_price_test,predictions_price_5633)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_5633, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_5633, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_5633, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_5633, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_5633, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_5633, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_5633, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_5633, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_price_test,predictions_price_5633, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_price_test,predictions_price_5633, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0 152   0]\n",
      " [  0 419   0]\n",
      " [  0 221   0]]\n",
      "\n",
      "Accuracy: 0.53\n",
      "\n",
      "Micro Precision: 0.53\n",
      "Micro Recall: 0.53\n",
      "Micro F1-score: 0.53\n",
      "\n",
      "Macro Precision: 0.18\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.23\n",
      "\n",
      "Weighted Precision: 0.28\n",
      "Weighted Recall: 0.53\n",
      "Weighted F1-score: 0.37\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       152\n",
      "           0       0.53      1.00      0.69       419\n",
      "           1       0.00      0.00      0.00       221\n",
      "\n",
      "    accuracy                           0.53       792\n",
      "   macro avg       0.18      0.33      0.23       792\n",
      "weighted avg       0.28      0.53      0.37       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Price Pada K = 7 dengan fitur seleksi 3755\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_price_test,predictions_price_3755)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_price_test,predictions_price_3755)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_3755, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_3755, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_3755, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_3755, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_3755, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_3755, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_3755, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_3755, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_price_test,predictions_price_3755, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_price_test,predictions_price_3755, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0 152   0]\n",
      " [  0 419   0]\n",
      " [  0 221   0]]\n",
      "\n",
      "Accuracy: 0.53\n",
      "\n",
      "Micro Precision: 0.53\n",
      "Micro Recall: 0.53\n",
      "Micro F1-score: 0.53\n",
      "\n",
      "Macro Precision: 0.18\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.23\n",
      "\n",
      "Weighted Precision: 0.28\n",
      "Weighted Recall: 0.53\n",
      "Weighted F1-score: 0.37\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       152\n",
      "           0       0.53      1.00      0.69       419\n",
      "           1       0.00      0.00      0.00       221\n",
      "\n",
      "    accuracy                           0.53       792\n",
      "   macro avg       0.18      0.33      0.23       792\n",
      "weighted avg       0.28      0.53      0.37       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Price Pada K = 7 dengan fitur seleksi 2253\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_price_test,predictions_price_2253)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_price_test,predictions_price_2253)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_2253, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_2253, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_2253, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_2253, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_2253, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_2253, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_2253, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_2253, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_price_test,predictions_price_2253, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_price_test,predictions_price_2253, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0 152   0]\n",
      " [  0 419   0]\n",
      " [  1 220   0]]\n",
      "\n",
      "Accuracy: 0.53\n",
      "\n",
      "Micro Precision: 0.53\n",
      "Micro Recall: 0.53\n",
      "Micro F1-score: 0.53\n",
      "\n",
      "Macro Precision: 0.18\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.23\n",
      "\n",
      "Weighted Precision: 0.28\n",
      "Weighted Recall: 0.53\n",
      "Weighted F1-score: 0.37\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       152\n",
      "           0       0.53      1.00      0.69       419\n",
      "           1       0.00      0.00      0.00       221\n",
      "\n",
      "    accuracy                           0.53       792\n",
      "   macro avg       0.18      0.33      0.23       792\n",
      "weighted avg       0.28      0.53      0.37       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Price Pada K = 7 dengan fitur seleksi 376\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_price_test,predictions_price_376)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_price_test,predictions_price_376)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_376, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_376, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_376, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_376, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_376, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_376, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_376, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_376, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_price_test,predictions_price_376, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_price_test,predictions_price_376, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[ 11 130  11]\n",
      " [ 12 402   5]\n",
      " [  5 206  10]]\n",
      "\n",
      "Accuracy: 0.53\n",
      "\n",
      "Micro Precision: 0.53\n",
      "Micro Recall: 0.53\n",
      "Micro F1-score: 0.53\n",
      "\n",
      "Macro Precision: 0.44\n",
      "Macro Recall: 0.36\n",
      "Macro F1-score: 0.30\n",
      "\n",
      "Weighted Precision: 0.47\n",
      "Weighted Recall: 0.53\n",
      "Weighted F1-score: 0.41\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      0.07      0.12       152\n",
      "           0       0.54      0.96      0.69       419\n",
      "           1       0.38      0.05      0.08       221\n",
      "\n",
      "    accuracy                           0.53       792\n",
      "   macro avg       0.44      0.36      0.30       792\n",
      "weighted avg       0.47      0.53      0.41       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Price Pada K = 7 dengan fitur seleksi 76\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_price_test,predictions_price_76)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_price_test,predictions_price_76)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_76, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_76, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_76, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_76, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_76, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_76, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_76, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_76, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_price_test,predictions_price_76, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_price_test,predictions_price_76, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  2 122  28]\n",
      " [  2 383  34]\n",
      " [ 46 170   5]]\n",
      "\n",
      "Accuracy: 0.49\n",
      "\n",
      "Micro Precision: 0.49\n",
      "Micro Recall: 0.49\n",
      "Micro F1-score: 0.49\n",
      "\n",
      "Macro Precision: 0.23\n",
      "Macro Recall: 0.32\n",
      "Macro F1-score: 0.25\n",
      "\n",
      "Weighted Precision: 0.33\n",
      "Weighted Recall: 0.49\n",
      "Weighted F1-score: 0.38\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.04      0.01      0.02       152\n",
      "           0       0.57      0.91      0.70       419\n",
      "           1       0.07      0.02      0.03       221\n",
      "\n",
      "    accuracy                           0.49       792\n",
      "   macro avg       0.23      0.32      0.25       792\n",
      "weighted avg       0.33      0.49      0.38       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Price Pada K = 7 dengan fitur seleksi 30\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_price_test,predictions_price_30)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_price_test,predictions_price_30)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_30, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_30, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_30, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_30, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_30, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_price_test,predictions_price_30, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_price_test,predictions_price_30, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_price_test,predictions_price_30, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_price_test,predictions_price_30, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_price_test,predictions_price_30, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  39   2]\n",
      " [  0 671   1]\n",
      " [  0  78   1]]\n",
      "\n",
      "Accuracy: 0.85\n",
      "\n",
      "Micro Precision: 0.85\n",
      "Micro Recall: 0.85\n",
      "Micro F1-score: 0.85\n",
      "\n",
      "Macro Precision: 0.37\n",
      "Macro Recall: 0.34\n",
      "Macro F1-score: 0.31\n",
      "\n",
      "Weighted Precision: 0.75\n",
      "Weighted Recall: 0.85\n",
      "Weighted F1-score: 0.78\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        41\n",
      "           0       0.85      1.00      0.92       672\n",
      "           1       0.25      0.01      0.02        79\n",
      "\n",
      "    accuracy                           0.85       792\n",
      "   macro avg       0.37      0.34      0.31       792\n",
      "weighted avg       0.75      0.85      0.78       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Packaging pada K= 7 tanpa seleksi\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_packaging_test,predictions_packaging_all)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_packaging_test,predictions_packaging_all)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_all, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_all, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_all, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_all, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_all, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_all, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_all, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_all, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_packaging_test,predictions_packaging_all, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_packaging_test,predictions_packaging_all, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  41   0]\n",
      " [  0 672   0]\n",
      " [  0  79   0]]\n",
      "\n",
      "Accuracy: 0.85\n",
      "\n",
      "Micro Precision: 0.85\n",
      "Micro Recall: 0.85\n",
      "Micro F1-score: 0.85\n",
      "\n",
      "Macro Precision: 0.28\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.31\n",
      "\n",
      "Weighted Precision: 0.72\n",
      "Weighted Recall: 0.85\n",
      "Weighted F1-score: 0.78\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        41\n",
      "           0       0.85      1.00      0.92       672\n",
      "           1       0.00      0.00      0.00        79\n",
      "\n",
      "    accuracy                           0.85       792\n",
      "   macro avg       0.28      0.33      0.31       792\n",
      "weighted avg       0.72      0.85      0.78       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Packaging pada K= 7 dengan fitur seleksi 5633\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_packaging_test,predictions_packaging_5633)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_packaging_test,predictions_packaging_5633)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_5633, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_5633, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_5633, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_5633, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_5633, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_5633, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_5633, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_5633, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_packaging_test,predictions_packaging_5633, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_packaging_test,predictions_packaging_5633, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  41   0]\n",
      " [  0 672   0]\n",
      " [  0  79   0]]\n",
      "\n",
      "Accuracy: 0.85\n",
      "\n",
      "Micro Precision: 0.85\n",
      "Micro Recall: 0.85\n",
      "Micro F1-score: 0.85\n",
      "\n",
      "Macro Precision: 0.28\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.31\n",
      "\n",
      "Weighted Precision: 0.72\n",
      "Weighted Recall: 0.85\n",
      "Weighted F1-score: 0.78\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        41\n",
      "           0       0.85      1.00      0.92       672\n",
      "           1       0.00      0.00      0.00        79\n",
      "\n",
      "    accuracy                           0.85       792\n",
      "   macro avg       0.28      0.33      0.31       792\n",
      "weighted avg       0.72      0.85      0.78       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Packaging pada K= 7 dengan fitur seleksi 3755\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_packaging_test,predictions_packaging_3755)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_packaging_test,predictions_packaging_3755)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_3755, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_3755, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_3755, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_3755, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_3755, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_3755, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_3755, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_3755, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_packaging_test,predictions_packaging_3755, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_packaging_test,predictions_packaging_3755, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  41   0]\n",
      " [  0 672   0]\n",
      " [  0  79   0]]\n",
      "\n",
      "Accuracy: 0.85\n",
      "\n",
      "Micro Precision: 0.85\n",
      "Micro Recall: 0.85\n",
      "Micro F1-score: 0.85\n",
      "\n",
      "Macro Precision: 0.28\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.31\n",
      "\n",
      "Weighted Precision: 0.72\n",
      "Weighted Recall: 0.85\n",
      "Weighted F1-score: 0.78\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        41\n",
      "           0       0.85      1.00      0.92       672\n",
      "           1       0.00      0.00      0.00        79\n",
      "\n",
      "    accuracy                           0.85       792\n",
      "   macro avg       0.28      0.33      0.31       792\n",
      "weighted avg       0.72      0.85      0.78       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Packaging pada K= 7 dengan fitur seleksi 2253\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_packaging_test,predictions_packaging_2253)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_packaging_test,predictions_packaging_2253)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_2253, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_2253, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_2253, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_2253, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_2253, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_2253, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_2253, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_2253, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_packaging_test,predictions_packaging_2253, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_packaging_test,predictions_packaging_2253, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  41   0]\n",
      " [  0 671   1]\n",
      " [  0  79   0]]\n",
      "\n",
      "Accuracy: 0.85\n",
      "\n",
      "Micro Precision: 0.85\n",
      "Micro Recall: 0.85\n",
      "Micro F1-score: 0.85\n",
      "\n",
      "Macro Precision: 0.28\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.31\n",
      "\n",
      "Weighted Precision: 0.72\n",
      "Weighted Recall: 0.85\n",
      "Weighted F1-score: 0.78\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        41\n",
      "           0       0.85      1.00      0.92       672\n",
      "           1       0.00      0.00      0.00        79\n",
      "\n",
      "    accuracy                           0.85       792\n",
      "   macro avg       0.28      0.33      0.31       792\n",
      "weighted avg       0.72      0.85      0.78       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Packaging pada K= 7 dengan fitur seleksi 376\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_packaging_test,predictions_packaging_376)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_packaging_test,predictions_packaging_376)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_376, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_376, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_376, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_376, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_376, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_376, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_376, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_376, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_packaging_test,predictions_packaging_376, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_packaging_test,predictions_packaging_376, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  36   5]\n",
      " [  0 670   2]\n",
      " [  0  76   3]]\n",
      "\n",
      "Accuracy: 0.85\n",
      "\n",
      "Micro Precision: 0.85\n",
      "Micro Recall: 0.85\n",
      "Micro F1-score: 0.85\n",
      "\n",
      "Macro Precision: 0.39\n",
      "Macro Recall: 0.34\n",
      "Macro F1-score: 0.33\n",
      "\n",
      "Weighted Precision: 0.76\n",
      "Weighted Recall: 0.85\n",
      "Weighted F1-score: 0.79\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        41\n",
      "           0       0.86      1.00      0.92       672\n",
      "           1       0.30      0.04      0.07        79\n",
      "\n",
      "    accuracy                           0.85       792\n",
      "   macro avg       0.39      0.34      0.33       792\n",
      "weighted avg       0.76      0.85      0.79       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Packaging pada K= 7 dengan fitur seleksi 76\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_packaging_test,predictions_packaging_76)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_packaging_test,predictions_packaging_76)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_76, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_76, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_76, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_76, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_76, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_76, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_76, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_76, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_packaging_test,predictions_packaging_76, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_packaging_test,predictions_packaging_76, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  36   5]\n",
      " [  0 667   5]\n",
      " [  0  77   2]]\n",
      "\n",
      "Accuracy: 0.84\n",
      "\n",
      "Micro Precision: 0.84\n",
      "Micro Recall: 0.84\n",
      "Micro F1-score: 0.84\n",
      "\n",
      "Macro Precision: 0.34\n",
      "Macro Recall: 0.34\n",
      "Macro F1-score: 0.32\n",
      "\n",
      "Weighted Precision: 0.74\n",
      "Weighted Recall: 0.84\n",
      "Weighted F1-score: 0.78\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        41\n",
      "           0       0.86      0.99      0.92       672\n",
      "           1       0.17      0.03      0.04        79\n",
      "\n",
      "    accuracy                           0.84       792\n",
      "   macro avg       0.34      0.34      0.32       792\n",
      "weighted avg       0.74      0.84      0.78       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Packaging pada K= 7 dengan fitur seleksi 30\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_packaging_test,predictions_packaging_30)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_packaging_test,predictions_packaging_30)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_30, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_30, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_30, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_30, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_30, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_packaging_test,predictions_packaging_30, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_packaging_test,predictions_packaging_30, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_packaging_test,predictions_packaging_30, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_packaging_test,predictions_packaging_30, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_packaging_test,predictions_packaging_30, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[ 13   1 121]\n",
      " [  4  22  95]\n",
      " [  3   3 530]]\n",
      "\n",
      "Accuracy: 0.71\n",
      "\n",
      "Micro Precision: 0.71\n",
      "Micro Recall: 0.71\n",
      "Micro F1-score: 0.71\n",
      "\n",
      "Macro Precision: 0.74\n",
      "Macro Recall: 0.42\n",
      "Macro F1-score: 0.43\n",
      "\n",
      "Weighted Precision: 0.72\n",
      "Weighted Recall: 0.71\n",
      "Weighted F1-score: 0.63\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.10      0.17       135\n",
      "           0       0.85      0.18      0.30       121\n",
      "           1       0.71      0.99      0.83       536\n",
      "\n",
      "    accuracy                           0.71       792\n",
      "   macro avg       0.74      0.42      0.43       792\n",
      "weighted avg       0.72      0.71      0.63       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 tanpa seleksi\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_product_test,predictions_product_all)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_product_test,predictions_product_all)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_all, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_all, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_all, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_all, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_all, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_all, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_all, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_all, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_product_test,predictions_product_all, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_product_test,predictions_product_all, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0   0 135]\n",
      " [  0   0 121]\n",
      " [  0   0 536]]\n",
      "\n",
      "Accuracy: 0.68\n",
      "\n",
      "Micro Precision: 0.68\n",
      "Micro Recall: 0.68\n",
      "Micro F1-score: 0.68\n",
      "\n",
      "Macro Precision: 0.23\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.27\n",
      "\n",
      "Weighted Precision: 0.46\n",
      "Weighted Recall: 0.68\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       135\n",
      "           0       0.00      0.00      0.00       121\n",
      "           1       0.68      1.00      0.81       536\n",
      "\n",
      "    accuracy                           0.68       792\n",
      "   macro avg       0.23      0.33      0.27       792\n",
      "weighted avg       0.46      0.68      0.55       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 5633\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_product_test,predictions_product_5633)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_product_test,predictions_product_5633)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_5633, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_5633, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_5633, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_5633, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_5633, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_5633, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_5633, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_5633, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_product_test,predictions_product_5633, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_product_test,predictions_product_5633, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0   0 135]\n",
      " [  0   0 121]\n",
      " [  0   0 536]]\n",
      "\n",
      "Accuracy: 0.68\n",
      "\n",
      "Micro Precision: 0.68\n",
      "Micro Recall: 0.68\n",
      "Micro F1-score: 0.68\n",
      "\n",
      "Macro Precision: 0.23\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.27\n",
      "\n",
      "Weighted Precision: 0.46\n",
      "Weighted Recall: 0.68\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       135\n",
      "           0       0.00      0.00      0.00       121\n",
      "           1       0.68      1.00      0.81       536\n",
      "\n",
      "    accuracy                           0.68       792\n",
      "   macro avg       0.23      0.33      0.27       792\n",
      "weighted avg       0.46      0.68      0.55       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 3755\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_product_test,predictions_product_3755)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_product_test,predictions_product_3755)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_3755, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_3755, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_3755, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_3755, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_3755, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_3755, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_3755, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_3755, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_product_test,predictions_product_3755, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_product_test,predictions_product_3755, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0   0 135]\n",
      " [  0   0 121]\n",
      " [  0   0 536]]\n",
      "\n",
      "Accuracy: 0.68\n",
      "\n",
      "Micro Precision: 0.68\n",
      "Micro Recall: 0.68\n",
      "Micro F1-score: 0.68\n",
      "\n",
      "Macro Precision: 0.23\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.27\n",
      "\n",
      "Weighted Precision: 0.46\n",
      "Weighted Recall: 0.68\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       135\n",
      "           0       0.00      0.00      0.00       121\n",
      "           1       0.68      1.00      0.81       536\n",
      "\n",
      "    accuracy                           0.68       792\n",
      "   macro avg       0.23      0.33      0.27       792\n",
      "weighted avg       0.46      0.68      0.55       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 2253\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_product_test,predictions_product_2253)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_product_test,predictions_product_2253)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_2253, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_2253, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_2253, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_2253, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_2253, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_2253, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_2253, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_2253, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_product_test,predictions_product_2253, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_product_test,predictions_product_2253, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0   0 135]\n",
      " [  0   0 121]\n",
      " [  0   0 536]]\n",
      "\n",
      "Accuracy: 0.68\n",
      "\n",
      "Micro Precision: 0.68\n",
      "Micro Recall: 0.68\n",
      "Micro F1-score: 0.68\n",
      "\n",
      "Macro Precision: 0.23\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.27\n",
      "\n",
      "Weighted Precision: 0.46\n",
      "Weighted Recall: 0.68\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       135\n",
      "           0       0.00      0.00      0.00       121\n",
      "           1       0.68      1.00      0.81       536\n",
      "\n",
      "    accuracy                           0.68       792\n",
      "   macro avg       0.23      0.33      0.27       792\n",
      "weighted avg       0.46      0.68      0.55       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 376\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_product_test,predictions_product_376)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_product_test,predictions_product_376)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_376, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_376, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_376, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_376, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_376, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_376, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_376, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_376, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_product_test,predictions_product_376, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_product_test,predictions_product_376, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  2   0 133]\n",
      " [  2   0 119]\n",
      " [  0   1 535]]\n",
      "\n",
      "Accuracy: 0.68\n",
      "\n",
      "Micro Precision: 0.68\n",
      "Micro Recall: 0.68\n",
      "Micro F1-score: 0.68\n",
      "\n",
      "Macro Precision: 0.39\n",
      "Macro Recall: 0.34\n",
      "Macro F1-score: 0.28\n",
      "\n",
      "Weighted Precision: 0.55\n",
      "Weighted Recall: 0.68\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.01      0.03       135\n",
      "           0       0.00      0.00      0.00       121\n",
      "           1       0.68      1.00      0.81       536\n",
      "\n",
      "    accuracy                           0.68       792\n",
      "   macro avg       0.39      0.34      0.28       792\n",
      "weighted avg       0.55      0.68      0.55       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 76\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_product_test,predictions_product_76)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_product_test,predictions_product_76)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_76, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_76, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_76, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_76, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_76, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_76, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_76, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_76, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_product_test,predictions_product_76, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_product_test,predictions_product_76, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  5   1 129]\n",
      " [ 10   6 105]\n",
      " [  3   0 533]]\n",
      "\n",
      "Accuracy: 0.69\n",
      "\n",
      "Micro Precision: 0.69\n",
      "Micro Recall: 0.69\n",
      "Micro F1-score: 0.69\n",
      "\n",
      "Macro Precision: 0.61\n",
      "Macro Recall: 0.36\n",
      "Macro F1-score: 0.33\n",
      "\n",
      "Weighted Precision: 0.65\n",
      "Weighted Recall: 0.69\n",
      "Weighted F1-score: 0.58\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.28      0.04      0.07       135\n",
      "           0       0.86      0.05      0.09       121\n",
      "           1       0.69      0.99      0.82       536\n",
      "\n",
      "    accuracy                           0.69       792\n",
      "   macro avg       0.61      0.36      0.33       792\n",
      "weighted avg       0.65      0.69      0.58       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 30\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_product_test,predictions_product_30)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_product_test,predictions_product_30)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_30, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_30, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_30, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_30, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_30, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_product_test,predictions_product_30, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_product_test,predictions_product_30, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_product_test,predictions_product_30, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_product_test,predictions_product_30, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_product_test,predictions_product_30, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  38   2]\n",
      " [  0 612   3]\n",
      " [  0 118  19]]\n",
      "\n",
      "Accuracy: 0.80\n",
      "\n",
      "Micro Precision: 0.80\n",
      "Micro Recall: 0.80\n",
      "Micro F1-score: 0.80\n",
      "\n",
      "Macro Precision: 0.53\n",
      "Macro Recall: 0.38\n",
      "Macro F1-score: 0.37\n",
      "\n",
      "Weighted Precision: 0.76\n",
      "Weighted Recall: 0.80\n",
      "Weighted F1-score: 0.73\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        40\n",
      "           0       0.80      1.00      0.89       615\n",
      "           1       0.79      0.14      0.24       137\n",
      "\n",
      "    accuracy                           0.80       792\n",
      "   macro avg       0.53      0.38      0.37       792\n",
      "weighted avg       0.76      0.80      0.73       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Aroma pada K= 7 tanpa seleksi\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_aroma_test,predictions_aroma_all)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_aroma_test,predictions_aroma_all)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_all, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_all, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_all, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_all, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_all, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_all, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_all, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_all, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_aroma_test,predictions_aroma_all, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_aroma_test,predictions_aroma_all, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  40   0]\n",
      " [  0 615   0]\n",
      " [  0 137   0]]\n",
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Micro Precision: 0.78\n",
      "Micro Recall: 0.78\n",
      "Micro F1-score: 0.78\n",
      "\n",
      "Macro Precision: 0.26\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.29\n",
      "\n",
      "Weighted Precision: 0.60\n",
      "Weighted Recall: 0.78\n",
      "Weighted F1-score: 0.68\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        40\n",
      "           0       0.78      1.00      0.87       615\n",
      "           1       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.78       792\n",
      "   macro avg       0.26      0.33      0.29       792\n",
      "weighted avg       0.60      0.78      0.68       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 5633\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_aroma_test,predictions_aroma_5633)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_aroma_test,predictions_aroma_5633)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_5633, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_5633, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_5633, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_5633, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_5633, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_5633, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_5633, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_5633, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_aroma_test,predictions_aroma_5633, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_aroma_test,predictions_aroma_5633, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  40   0]\n",
      " [  0 615   0]\n",
      " [  0 137   0]]\n",
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Micro Precision: 0.78\n",
      "Micro Recall: 0.78\n",
      "Micro F1-score: 0.78\n",
      "\n",
      "Macro Precision: 0.26\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.29\n",
      "\n",
      "Weighted Precision: 0.60\n",
      "Weighted Recall: 0.78\n",
      "Weighted F1-score: 0.68\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        40\n",
      "           0       0.78      1.00      0.87       615\n",
      "           1       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.78       792\n",
      "   macro avg       0.26      0.33      0.29       792\n",
      "weighted avg       0.60      0.78      0.68       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 3755\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_aroma_test,predictions_aroma_3755)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_aroma_test,predictions_aroma_3755)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_3755, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_3755, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_3755, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_3755, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_3755, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_3755, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_3755, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_3755, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_aroma_test,predictions_aroma_3755, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_aroma_test,predictions_aroma_3755, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  40   0]\n",
      " [  0 615   0]\n",
      " [  0 137   0]]\n",
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Micro Precision: 0.78\n",
      "Micro Recall: 0.78\n",
      "Micro F1-score: 0.78\n",
      "\n",
      "Macro Precision: 0.26\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.29\n",
      "\n",
      "Weighted Precision: 0.60\n",
      "Weighted Recall: 0.78\n",
      "Weighted F1-score: 0.68\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        40\n",
      "           0       0.78      1.00      0.87       615\n",
      "           1       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.78       792\n",
      "   macro avg       0.26      0.33      0.29       792\n",
      "weighted avg       0.60      0.78      0.68       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 2253\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_aroma_test,predictions_aroma_2253)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_aroma_test,predictions_aroma_2253)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_2253, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_2253, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_2253, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_2253, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_2253, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_2253, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_2253, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_2253, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_aroma_test,predictions_aroma_2253, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_aroma_test,predictions_aroma_2253, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  39   1]\n",
      " [  0 615   0]\n",
      " [  0 136   1]]\n",
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Micro Precision: 0.78\n",
      "Micro Recall: 0.78\n",
      "Micro F1-score: 0.78\n",
      "\n",
      "Macro Precision: 0.43\n",
      "Macro Recall: 0.34\n",
      "Macro F1-score: 0.30\n",
      "\n",
      "Weighted Precision: 0.69\n",
      "Weighted Recall: 0.78\n",
      "Weighted F1-score: 0.68\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        40\n",
      "           0       0.78      1.00      0.88       615\n",
      "           1       0.50      0.01      0.01       137\n",
      "\n",
      "    accuracy                           0.78       792\n",
      "   macro avg       0.43      0.34      0.30       792\n",
      "weighted avg       0.69      0.78      0.68       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 376\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_aroma_test,predictions_aroma_376)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_aroma_test,predictions_aroma_376)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_376, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_376, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_376, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_376, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_376, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_376, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_376, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_376, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_aroma_test,predictions_aroma_376, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_aroma_test,predictions_aroma_376, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  1  36   3]\n",
      " [  0 614   1]\n",
      " [  0 123  14]]\n",
      "\n",
      "Accuracy: 0.79\n",
      "\n",
      "Micro Precision: 0.79\n",
      "Micro Recall: 0.79\n",
      "Micro F1-score: 0.79\n",
      "\n",
      "Macro Precision: 0.86\n",
      "Macro Recall: 0.38\n",
      "Macro F1-score: 0.37\n",
      "\n",
      "Weighted Precision: 0.80\n",
      "Weighted Recall: 0.79\n",
      "Weighted F1-score: 0.72\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.03      0.05        40\n",
      "           0       0.79      1.00      0.88       615\n",
      "           1       0.78      0.10      0.18       137\n",
      "\n",
      "    accuracy                           0.79       792\n",
      "   macro avg       0.86      0.38      0.37       792\n",
      "weighted avg       0.80      0.79      0.72       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 76\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_aroma_test,predictions_aroma_76)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_aroma_test,predictions_aroma_76)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_76, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_76, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_76, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_76, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_76, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_76, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_76, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_76, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_aroma_test,predictions_aroma_76, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_aroma_test,predictions_aroma_76, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0  31   9]\n",
      " [  0 593  22]\n",
      " [  0 123  14]]\n",
      "\n",
      "Accuracy: 0.77\n",
      "\n",
      "Micro Precision: 0.77\n",
      "Micro Recall: 0.77\n",
      "Micro F1-score: 0.77\n",
      "\n",
      "Macro Precision: 0.37\n",
      "Macro Recall: 0.36\n",
      "Macro F1-score: 0.34\n",
      "\n",
      "Weighted Precision: 0.67\n",
      "Weighted Recall: 0.77\n",
      "Weighted F1-score: 0.70\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        40\n",
      "           0       0.79      0.96      0.87       615\n",
      "           1       0.31      0.10      0.15       137\n",
      "\n",
      "    accuracy                           0.77       792\n",
      "   macro avg       0.37      0.36      0.34       792\n",
      "weighted avg       0.67      0.77      0.70       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluasi aspek Product pada K= 7 dengan fitur seleksi 30\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_aroma_test,predictions_aroma_30)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_aroma_test,predictions_aroma_30)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_30, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_30, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_30, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_30, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_30, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_aroma_test,predictions_aroma_30, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_aroma_test,predictions_aroma_30, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_aroma_test,predictions_aroma_30, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_aroma_test,predictions_aroma_30, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_aroma_test,predictions_aroma_30, target_names=['-1', '0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
